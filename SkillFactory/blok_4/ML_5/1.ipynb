{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    " \n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "plt.style.use('seaborn') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_data = pd.read_csv('water_potability.csv')\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Невооруженным глазом видно, что большинство столбцов таблицы являются числовыми. Целевой признак — Potability (пригодность для питья): \n",
    "\n",
    "1 — вода пригодна, \n",
    "\n",
    "0 — вода не пригодна.\n",
    "\n",
    "В данных есть пропуски. Выведем информацию о них в процентном соотношении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 14.987790\n",
       "Hardness            0.000000\n",
       "Solids              0.000000\n",
       "Chloramines         0.000000\n",
       "Sulfate            23.840049\n",
       "Conductivity        0.000000\n",
       "Organic_carbon      0.000000\n",
       "Trihalomethanes     4.945055\n",
       "Turbidity           0.000000\n",
       "Potability          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас отсутствует около 15 % информации о кислотности воды (ph), около 24 % — о содержании сульфатов (Sulfate) и около 5 % — о тригалометанах (Trihalomethanes). Мы знаем, что пропуски — непосильная ноша для большинства моделей машинного обучения. Их необходимо обработать.\n",
    "\n",
    "Заполним пропуски медианным значением в признаке зависимости класса воды (Potability). Для этого сгруппируем данные по признаку Potability, посчитаем медиану в каждой группе, а затем отправим результат в метод fillna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполняем пропуски\n",
    "water_data['ph'] = water_data['ph'].fillna(water_data.groupby('Potability')['ph'].transform('median'))\n",
    "water_data['Sulfate'] = water_data['Sulfate'].fillna(water_data.groupby('Potability')['Sulfate'].transform('median'))\n",
    "water_data['Trihalomethanes'] = water_data['Trihalomethanes'].fillna(water_data.groupby('Potability')['Trihalomethanes'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0.0\n",
       "Hardness           0.0\n",
       "Solids             0.0\n",
       "Chloramines        0.0\n",
       "Sulfate            0.0\n",
       "Conductivity       0.0\n",
       "Organic_carbon     0.0\n",
       "Trihalomethanes    0.0\n",
       "Turbidity          0.0\n",
       "Potability         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Убедимся в отсутствии пропусков:\n",
    "\n",
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь проблема пропусков устранена. \n",
    "# Давайте по традиции разделим набор данных \n",
    "# на матрицу наблюдений X и вектор правильных ответов y:\n",
    "\n",
    "X = water_data.drop('Potability', axis=1)\n",
    "y = water_data['Potability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "основные методы валидации данных ↓\n",
    "\n",
    "### HOLD-OUT\n",
    "\n",
    "Обычно разбиение производится в соотношении 70/30 или 80/20 при двухкомпонентном подходе, и в соотношении 70/15/15 или 80/10/10 — при трёхкомпонентном.\n",
    "\n",
    "РЕАЛИЗАЦИЯ МЕТОДА В SKLEARN\n",
    "\n",
    "Все методы разбиения выборки и валидации, которые мы будем изучать, находятся в модуле model_selection, мы импортировали его заранее.\n",
    "\n",
    "Метод hold-out реализован в уже знакомой вам функции train_test_split(). Она предназначена для разбиения исходного набора данных случайным образом на две части в заданных соотношениях\n",
    "\n",
    "Основные параметры *train_test_split()*:\n",
    "\n",
    "- *arrays — порядковый аргумент с переменным количеством. Набор массивов (это могут быть списки, numpy-массивы, DataFrame), которые подлежат разбиению.\n",
    "- test_size — размер тестовой (валидационной) выборки. Может быть указан в долях. Определяется автоматически, если параметр test_size передан как 1-train_size.\n",
    "- train_size — размер тренировочной выборки. Может быть указан в долях. Определяется автоматически, если параметр test_size передан как 1-test_size.\n",
    "- random_state — число, на основе которого производится генерация случайных чисел.\n",
    "- shuffle — параметр, указывающий, стоит ли перемешивать выборку перед разбиением (по умолчанию True).\n",
    "- stratify — стратифицированное разбиение (о нём мы поговорим в юните по дисбалансу выборки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера разделим выборку в соотношении 80/20 (test_size=0.2), в качестве значения параметра random_state по традиции возьмём число 42.\n",
    "\n",
    "Функция вернёт четыре массива:\n",
    "\n",
    "- таблицу X с обучающими примерами,\n",
    "- таблицу X с примерами для валидации,\n",
    "- столбец y с ответами на обучающие примеры,\n",
    "- столбец y с ответами на валидационные примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (656, 9)\n"
     ]
    }
   ],
   "source": [
    "# Проверим размеры полученных выборок:\n",
    "\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, 2 620 образцов воды являются обучающими — в них модель будет искать закономерности и подбирать внутренние параметры, а 656 являются валидационными — на них мы будем производить контроль качества.\n",
    "\n",
    "Далее нам останется только обучить модель на тренировочной выборке (X_train, y_train) и рассчитать метрики на валидационной выборке (X_valid, y_valid).\n",
    "\n",
    "В качестве модели будем использовать дерево решений с максимальной глубиной 7, энтропией в качестве критерия информативности, минимальное число объектов в листе дерева — 5.\n",
    "\n",
    "После обучения сделаем предсказание для каждой из выборок и рассчитаем метрику. В качестве метрики для простоты возьмём долю правильных ответов — *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hold-out accuracy: 0.82\n",
      "Valid hold-out accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print('Train hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_train, y_train_pred)))\n",
    "print('Valid hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_valid, y_valid_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же мы используем трёхкомпонентный подход (разбиваем выборку на тренировочную, валидационную и отдельную тестовую), тут нам понадобится чуть больше кода. К сожалению, в sklearn нет специализированного функционала для такого разбиения.\n",
    "\n",
    "Применим функцию train_test_split() дважды: сначала разобьём исходный набор на тренировочный и валидационный в соотношении 80/20, затем разобьём валидационный набор на валидационный и тестовый в соотношении 50/50. В итоге наша выборка будет разбита в соотношении 80/10/10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем исходную выборку на тренировочную и валидационную в соотношении 80/20\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = model_selection.train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (328, 9)\n",
      "Test shape: (328, 9)\n"
     ]
    }
   ],
   "source": [
    "# Выводим размерности:\n",
    "\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-FOLD\n",
    "\n",
    "Метод k-fold более известен как кросс-валидация (cross validation), или перекрёстный контроль.\n",
    "\n",
    "Пожалуй, это самый популярный метод валидации для оценки качества моделирования, и он используется практически во всех проектах. Эта идея также применяется во многих моделях и методах машинного обучения, например в стекинге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aлгоритм кросс-валидации:\n",
    "\n",
    "- Разбить исходную выборку на  частей — фолдов (fold).\n",
    "- Повторять  раз:\n",
    "    - Обучить модель на  частях. Назовём их тренировочными фолдами (training fold). \n",
    "    - Произвести оценку качества (вычислить метрику) на оставшейся части. Назовем её валидационным фолдом (validation fold).\n",
    "- Усреднить значения метрики на валидационных фолдах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке sklearn метод k-fold реализован в классе KFold.\n",
    "\n",
    "Основные параметры инициализатора KFold:\n",
    "\n",
    "- n_split —  число фолдов (число $k$ из метода k-fold). По умолчанию — 5.\n",
    "- shuffle — параметр, указывающий, стоит ли перемешивать исходный набор данных перед разбиением. По умолчанию — False.\n",
    "- random_state — число, на основе которого производится генерация случайных чисел, если набор данных будет перемешиваться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта класса KFold есть метод split(). В данный метод необходимо передать матрицу наблюдений X и вектор-столбец ответов y — метод вернёт генератор, который позволит получать индексы тренировочной и валидационной выборок, сгенерированных по методу k-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать двухкомпонентный контроль, то есть подавать в кросс-валидацию весь доступный набор данных без предварительного выделения тестовой выборки.\n",
    "\n",
    "Создадим объект KFold для кросс-валидации с пятью фолдами, остальные параметры оставим по умолчанию. Затем организуем цикл for для получения элементов из генератора, созданного с помощью метода split(). На каждой итерации в переменных train_index и valid_index будут находиться индексы текущей тренировочной и валидационной выборок соответственно.\n",
    "\n",
    "В цикле будем:\n",
    "\n",
    "- выделять строки таблицы, относящиеся к текущим тренировочной и валидационной выборкам, в отдельные таблицы;\n",
    "- обучать дерево решений;\n",
    "- делать предсказания для текущих тренировочной и валидационной выборок;\n",
    "- рассчитывать метрику accuracy на текущих выборках и заносить её значение в список.\n",
    "\n",
    "Код будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "#Создаём список для хранения тренировочных и валидационных метрик\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "#Организуем цикл для кросс-валидации (используем весь набор данных)\n",
    "#train_index — индексы тренировочной выборки\n",
    "#valid_index — индексы валидационной выборки\n",
    "for train_index, valid_index in kf.split(X, y): \n",
    "    #Создаём тренировочную и валидационную выборку, обращаясь по текущим индексам\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    #Обучаем случайный лес на тренировочной выборке\n",
    "    model.fit(X_train, y_train)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    #Рассчитываем метрику и заносим её в список\n",
    "    train_metrics.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    val_metrics.append(metrics.accuracy_score(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
      "[0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]\n"
     ]
    }
   ],
   "source": [
    "#Выведем содержимое массивов train_metrics и val_metrics:\n",
    "\n",
    "print(train_metrics)\n",
    "print(val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждом из выведенных списков содержится по пять значений метрики accuracy, вычисленных на тренировочном и валидационном фолдах кросс-валидации. Для агрегированной оценки рассчитаем среднее значение метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(train_metrics)))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(val_metrics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласитесь, сложновато — не совсем в стиле sklearn. Тут и циклы, и генераторы... Неужели каждый раз придётся писать подобный код для проведения кросс-валидации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно же, нет. На самом весь приведённый выше код можно значительно сократить, если использовать специальную функцию для кросс-валидации — *cross_validate()* из модуля *model_selection*. Она организует процедуру кросс-валидации и расчёт метрик.\n",
    "\n",
    "Основные параметры функции *cross_validate()*:\n",
    "\n",
    "- estimator — модель, качество которой будет проверяться на кросс-валидации.\n",
    "- X — матрица наблюдений.\n",
    "- y — вектор-столбец правильных ответов.\n",
    "- cv — кросс-валидатор из библиотеки sklearn (например, KFold) или количество фолдов, на которые необходимо разбить выборку. По умолчанию используется кросс-валидация на пяти фолдах.\n",
    "- scoring — название метрики в виде строки либо функция для её вычисления *('accuracy', 'precision', 'recall', 'f1'* и другие; полный список — в документации к функции).\n",
    "- return_train_score — параметр, указывающий стоит ли возвращать значения метрики, полученных на тренировочных фолдах. По умолчанию — False, то есть метрики считаются только на валидационных фолдах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция возвращает словарь со следующими ключами:\n",
    "\n",
    "- fit_time — время обучения модели на каждой итерации кросс-валидации;\n",
    "- score_time — время вычисления метрик на каждой итерации кросс-валидации;\n",
    "- test_score — значения метрик на валидационных фолдах;\n",
    "- train_score — значения метрик на тренировочных фолдах.\n",
    "\n",
    "Итоговый код с использованием функции cross_validate() будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04197311, 0.03997374, 0.03797483, 0.02998114, 0.02998018]),\n",
       " 'score_time': array([0.00406861, 0.00299931, 0.00100064, 0.00199866, 0.00199962]),\n",
       " 'test_score': array([0.79573171, 0.70534351, 0.73587786, 0.72824427, 0.73282443]),\n",
       " 'train_score': array([0.80343511, 0.81686379, 0.80274704, 0.82678367, 0.81571919])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=kf, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В массивах, хранящихся по ключам train_score и test_score, содержится по пять значений метрики accuracy, полученных на тренировочных и валидационных фолдах соответственно на каждой итерации кросс-валидации. Давайте рассчитаем среднее и сравним его с результатом, полученным ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили тот же результат, что и ранее. Согласитесь, функция cross_validate() значительно облегчает работу с кросс-валидацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAVE-ONE-OUT\n",
    "\n",
    "Метод leave-one-out (отложенный пример), или поэлементная кросс-валидация — это частный случай кросс-валидации (k-fold), когда размер $k$ равняется размеру всей выборки $k=n$, где $n$ — количество примеров (строк в таблице)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм метода:\n",
    "\n",
    "1. Повторять  раз:\n",
    "    - Выбрать один случайный пример для валидации.\n",
    "    - Обучить модель на всех оставшихся $n-1$ примерах.\n",
    "    - Произвести оценку качества (вычислить метрику) на отложенном примере.\n",
    "2. Усреднить значение метрик на всех примерах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РЕАЛИЗАЦИЯ МЕТОДА В SKLEARN\n",
    "\n",
    "В библиотеке sklearn метод leave-one-out реализован в классе LeaveOneOut. Параметров инициализации у данного класса нет.\n",
    "\n",
    "Работа с кросс-валидатором полностью идентична работе с KFold, который мы рассматривали ранее (цикл для организации кросс-валидации вручную будет выглядеть аналогично).\n",
    "\n",
    "Объект класса LeaveOneOut также можно передать в функцию cross_validate() для получения метрик на каждом из примеров. В случае с метрикой accuracy список будет состоять из 0 и 1 (0 — модель не угадала класс на отложенном примере, 1 — модель угадала класс на отложенном примере).\n",
    "\n",
    "Так как датасет у нас довольно большой (более трёх тысяч образцов воды), алгоритм кросс-валидации leave-one-out будет выполняться очень долго. Для экономии времени выполнения кода будем использовать первые 500 наблюдений из исходной таблицы.\n",
    "\n",
    "Примечание. Значение метрики будет рассчитано не для всего набора данных, а только для его части. Если вы захотите рассчитать метрику на всём наборе данных, вместо среза передавайте в функцию таблицу X и столбец y целиком. Но имейте в виду, что код в таком случае может выполняться до нескольких минут.\n",
    "\n",
    "Итоговый код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.95\n",
      "Valid k-fold mean accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём кросс-валидатор LeaveOneOut\n",
    "loo = model_selection.LeaveOneOut()\n",
    " \n",
    "#Считаем метрики на кросс-валидации leave-one-out\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X.iloc[:500], #матрица наблюдений X\n",
    "    y=y.iloc[:500], #вектор ответов y\n",
    "    cv=loo, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Метод leave-one-out можно реализовать и без использования специального класса — достаточно просто указать параметр n_split=n в инициализаторе KFold, где n — количество строк в таблице."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дисбаланс выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.60989\n",
       "1    0.39011\n",
       "Name: Potability, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Рассмотрим влияние дисбаланса на примере датасета о качестве воды.\n",
    "# Посмотрим на соотношения классов внутри датасета:\n",
    "\n",
    "display(water_data['Potability'].value_counts(normalize=True))\n",
    "sns.countplot(data=water_data, x='Potability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, около 61 % образцов воды являются непригодными для питья и 39 % являются пригодными. На самом деле это небольшой дисбаланс классов (61/39). В реальных задачах мы можете столкнуться и с куда более неравномерными соотношениями, например 80/20, 90/10 или даже 99/1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим особенности разбиения выборок в условиях дисбаланса классов.\n",
    "\n",
    "### СТРАТИФИЦИРОВАННОЕ РАЗБИЕНИЕ\n",
    "\n",
    "Для того чтобы снизить влияние дисбаланса классов при разбиении выборки, в наборе данных используется специальный тип разбиения, который называется стратифицированным (stratified). Данное разбиение предполагает, что наблюдения, принадлежащие каждому из классов, гарантированно попадут в каждый из наборов данных в одинаковой пропорции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте на на примере рассмотрим, как производить стратифицированное разбиение. Начнём с простого разделения hold-out, которое мы проводим с помощью функции train_test_split(). Для начала проведём обычное случайное разбиение на тренировочную и валидационную выборку (в соотношении 80/20) без стратификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.620229\n",
      "1    0.379771\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.568598\n",
      "1    0.431402\n",
      "Name: Potability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X, y = water_data.drop('Potability', axis=1), water_data['Potability']\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что соотношения классов в тренировочной выборке — 62/38, а в тестовой — 57/43. Давайте попробуем сбалансировать соотношения.\n",
    "\n",
    "Для стратифицированного разбиения достаточно в функции train_test_split() задать параметр stratify, в который нужно передать столбец с метками классов, на основе которого будет производиться балансировка. Это будет столбец с правильными ответами y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.609924\n",
      "1    0.390076\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.609756\n",
      "1    0.390244\n",
      "Name: Potability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)\n",
    "print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь в каждом из наборов данных одинаковые соотношения классов — 61/39. Метрики, полученные при одинаковых соотношениях на выборках, будут более объективными.\n",
    "\n",
    "**А что насчёт кросс-валидации? Как организовать разбиение по методу k-fold и получить одинаковые соотношения классов?**\n",
    "\n",
    "Для этого вместо KFold используется кросс-валидатор StratifiedKFold. Принцип работы с ним аналогичен, только, в отличие от KFold, StratifiedKFold будет разбивать выборку на части таким образом, чтобы в тренировочных и валидационных фолдах соотношения классов были приблизительно одинаковыми.\n",
    "\n",
    "Давайте напишем код, который организует стратифицированное k-fold-разбиение на три фолда, и выведем соотношения классов в каждой из выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n",
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n",
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "skf = model_selection.StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "for train_index, valid_index in skf.split(X, y): \n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "    print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что соотношения классов в тренировочной и валидационной выборках в каждом разбиении примерно одинаковы — 61/39.\n",
    "\n",
    "Так же, как и другие кросс-валидаторы, объект класса StratifiedKFold может быть использован в функции cross_validate()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.3\n",
    "\n",
    "\n",
    "Ниже представлен код для генерации задачи классификации и отрисовки диаграммы рассеяния с цветовой группировкой по классам:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте исходный набор данных на тренировочный и валидационный со стратификацией по классам в соотношении 80/20. В качестве значения параметра random_state возьмите число 42.\n",
    "\n",
    "Постройте диаграммы рассеяния с цветовой группировкой по классам для валидационной выборки.\n",
    "\n",
    "Из приведённых ниже диаграмм выберите ту, которая соответствует полученному разбиению:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВЫБОР МЕТРИК В УСЛОВИЯХ ДИСБАЛАНСА КЛАССОВ\n",
    "\n",
    "Давайте на примере посмотрим, насколько важен выбор метрики в случае дисбаланса выборки.\n",
    "\n",
    "Разобьём выборку на тренировочную и валидационную в соотношении 80/20, используя стратифицированное разбиение, затем обучим модель дерева решений, сделаем предсказание для каждой из выборок и сформируем отчёт о метриках на валидационной выборке с помощью функции classification_report()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       400\n",
      "           1       0.81      0.55      0.65       256\n",
      "\n",
      "    accuracy                           0.77       656\n",
      "   macro avg       0.78      0.73      0.74       656\n",
      "weighted avg       0.78      0.77      0.76       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print(metrics.classification_report(y_valid, y_valid_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из отчёта о метриках классификации видно, что для валидационной выборки метрика accuracy составляет 0.77, что, в принципе, является довольно хорошим результатом. Однако если мы посмотрим на метрики recall и f1-score для каждого из классов в отдельности, мы увидим, что метрики для класса 0 значительно выше, чем метрики для класса 1.\n",
    "\n",
    "- Precision для класса 1 составляет 0.81, то есть из всех образцов воды, причисленных моделью к классу пригодных для питья, 81 % действительно являются таковыми.\n",
    "- Recall для класса 1 составляет 0.55, то есть из всех образцов в действительности пригодной для питья воды модель посчитала пригодными лишь 55 %, а остальные 45 % посчитала непригодными.\n",
    "- $F1$-мера — среднее гармоническое между precision и recall — составила 0.65 для класса 1 и 0.83 — для класса 0. Разница довольно далека от нуля, а значит построенная нами модель больше контролируется на образцах воды, непригодных для питья, и обладает плохой различающей способностью.\n",
    "Однако мы не смогли бы выявить этот факт, если бы ориентировались только на метрику accuracy. Одной из причин такого результата является дисбаланс классов: образцов непригодной для питья попросту больше, чем пригодных для питья.\n",
    "\n",
    "Примечание. Поскольку простая accuracy вызывает сомнения в задачах с сильным дисбалансом, были разработаны специальные метрики, основанные на accuracy: это функционал Каппа Коэна (Cohen’s Kappa) и balanced accuracy. Подробнее о них вы можете прочитать здесь (https://dyakonov.org/2019/05/31/функционалы-качества-в-задаче-бинарн/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.5\n",
    "\n",
    "Для выполнения этого задания используйте сгенерированные тренировочную и валидационную выборки из задания 3.3.\n",
    "\n",
    "Обучите модель логистической регрессии на тренировочной выборке (все параметры оставьте по умолчанию).\n",
    "\n",
    "Сделайте предсказание для валидационной выборки и рассчитайте метрики классификации. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПОСТРОЕНИЕ МОДЕЛИ В УСЛОВИЯХ ДИСБАЛАНСА КЛАССОВ\n",
    "\n",
    "Итак, мы посмотрели, как дисбаланс выборки может оказывать влияние на способность модели находить класс меньшинства. Но как с этим бороться?\n",
    "\n",
    "Существует **несколько способов уменьшить влияние дисбаланса на обучение модели:**\n",
    "\n",
    "- **Взвешивание объектов.** В функцию ошибки добавляется штраф, прямо пропорциональный количеству объектов каждого класса. Это очень похоже на регуляризацию, которую мы изучали ранее.\n",
    "- **Выбор порога вероятности.** Этот подход мы с вами тоже уже использовали ранее. Он заключается в том, что мы подбираем такой порог вероятности (по умолчанию он равен 0.5 во всех моделях), при котором на валидационной выборке максимизируется целевая метрика (например, $F1$-score).\n",
    "- **Сэмплирование (sampling)** — перебалансировка выборки искусственным путём:\n",
    "oversampling — искусственное увеличение количества объектов миноритарного класса;\n",
    "undersampling — сокращение количества объектов мажоритарного класса.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь могут использоваться алгоритмы генерации искусственных данных, такие как NearMiss, SMOTE (Synthetic Minority Oversampling Techniques) и ADASYN (Adaptive Synthetic).\n",
    "\n",
    "Мы рассмотрим наиболее популярный алгоритм — SMOTE, об остальных можно прочитать здесь (https://dyakonov.org/2021/05/27/imbalance/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ВЗВЕШИВАНИЕ ОБЪЕКТОВ\n",
    "\n",
    "Для того чтобы задать веса классам, достаточно в инициализаторе модели выставить параметр class_weight='balanced'.\n",
    "\n",
    "Посмотрим на реализацию на примере дерева решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       400\n",
      "           1       0.63      0.76      0.69       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.72      0.73      0.72       656\n",
      "weighted avg       0.74      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик    \n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.7\n",
    "\n",
    "Для выполнения этого задания используйте сгенерированные тренировочную и валидационную выборки из задания 3.3.\n",
    "\n",
    "Обучите модель логистической регрессии на тренировочной выборке, уставив сбалансированные веса для классов.\n",
    "\n",
    "Сделайте предсказание для валидационной выборки и рассчитайте метрики классификации. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3.8 (на самопроверку)\n",
    "\n",
    "Воспользуйтесь функцией plot_probabilities_2d(), которую мы написали в модуле по классификации, для того, чтобы построить разделяющую поверхность логистической регрессии со сбалансированными весами классов.\n",
    "\n",
    "Примечание. Код функции plot_probabilities_2d() вы можете найти в задании 3.6.\n",
    "\n",
    "Передайте в её аргументы матрицу наблюдений X, вектор ответов y и обученную в задании 3.7 логистическую регрессию.\n",
    "\n",
    "Сравните разделяющую поверхность, построенную в задании 3.5, с полученной вами поверхностью в данном задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ВЫБОР ПОРОГА ВЕРОЯТНОСТИ. PR-КРИВАЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед построением PR-кривой нам необходимо предсказать вероятности принадлежности к классу 1 на валидационных фолдах кросс-валидации.\n",
    "\n",
    "Для предсказания вероятностей используем функцию cross_val_predict(). Данная функция выполняет кросс-валидацию и возвращает предсказания для валидационных фолдов. Если ей передать параметр method='predict_proba', она вернёт предсказанные вероятности для каждого из классов на всех фолдах. Остальные параметры аналогичны параметрам функции cross_validate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел \n",
    ")\n",
    "#Обучаем модель\n",
    "model.fit(X_train, y_train)\n",
    "#Создаём кросс-валидатор k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "#Делаем предсказание вероятностей на кросс-валидации\n",
    "y_cv_proba_pred = model_selection.cross_val_predict(model, X_train, y_train, cv=skf, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.24561404, 0.75438596],\n",
       "       [1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.60621762, 0.39378238],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03030303, 0.96969697]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv_proba_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это массив из вероятностей для каждого образца воды. Первое число в строке — вероятность того, что данный образец является непригодным для питья, а второе — вероятность того, что данный образец пригоден для питья.\n",
    "\n",
    "Нас интересует класс 1 (пригодная для питья вода). Это второй столбец в матрице вероятностей (индекс 1). Выделим этот столбец из матрицы с вероятностями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделяем столбец с вероятностями для класса 1 \n",
    "y_cv_proba_pred = y_cv_proba_pred[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем построить PR-кривую. Для этого воспользуемся функций precision_recall_curve() из модуля metrics библиотеки sklearn. В данную функцию нужно передать истинные метки классов и предсказанные вероятности. Взамен она вернёт три массива: значения метрик precision и recall, вычисленных на различных порогах вероятности, и сами пороги вероятности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds: [0.         0.02739726 0.02898551 0.05       0.07407407]\n",
      "Precision scores: [0.39007634 0.50050659 0.50357873 0.50437919 0.5043837 ]\n",
      "Recall scores: [1.         0.9667319  0.96379648 0.95792564 0.95694716]\n"
     ]
    }
   ],
   "source": [
    "#Вычисляем координаты PR-кривой\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_train, y_cv_proba_pred)\n",
    "\n",
    "print('Thresholds:', thresholds[:5])\n",
    "print('Precision scores:', precision[:5])\n",
    "print('Recall scores:',recall[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось дело за малым. Вычислим значение $F1$-score при различных порогах вероятности и найдём такой порог вероятности, при котором она максимальна. Сделать это можно с помощью функции argmax() из модуля numpy — она возвращает индекс максимального элемента массива.\n",
    "\n",
    "Далее построим PR-кривую и отметим на ней точку максимума $F1$-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold = 0.33, F1-Score = 0.69\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAFKCAYAAAAjTDqoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABEcUlEQVR4nO3dd3iV5eHG8e85J3uHDBIyCAnwgDIFZKiAUlTce9Zaa6e12lp3q9JWa9Wfto66q1Vrbd171C1T9oYnhBVmFknIIPv8/jgHjAhJgDMy7s915SLnvG/ec+fhEO4873K43W5EREREJDCcwQ4gIiIi0pOofImIiIgEkMqXiIiISACpfImIiIgEkMqXiIiISACpfImIiIgEUEiwA4hI52WMyQHWActbPe0AHrTWPuOj1/gjUGCtfb6NdZYAk621Fb54TX8yxnwBPAIsAFZYa2OCm0hEOhuVLxFpz25r7Yg9D4wxGcAKY8wCa+2yw924tfb2Dqwzor11RES6CpUvETko1tqtxpi1wEBjzFHAlUA0UGmtPd4YcyVwFZ7DGsqAq621a4wxMcDDwDFAE/Am8DvgWTwzRP9njPkDcDbQ4P3aH1prtxtj3ECKtbbUGHMbcLF3G/ne7e/wzjjN8W4/G5gBXG6tbWmd3zubNwNYDeQAk4B+wD3e76MFmG6tfde7/i3A5d7XWwv80Pv5Y8BAoBdQBVxirbUdGUNjzGnAnd4xqgF+DlTSaqbMm3OFtTbGGPPD1uMMhAMPWGtf9a77F8Bhrb3pQOPfkVwiEhg65ktEDooxZjzQH/ja+9SReHYJHm+MmYSnqBxnrR0J3Au87l3vj0AEMBgYgackTWq13Szg18AYa+1o4H/A2H1e+wpgmnedYcAK4J+tVskDJgNDgRNab38fmcCfrLUDgTo8BfAya+1RwBnAY8aYbGPMGXjK1nhr7RBgA3C1N0OFtXacdxvzvc+3yxjTG/gXnmI5DLgP+EsHvnTvOANPeXNhjHEB3weebmf8RaST0MyXiLQn0nvMFXh+ZpQCl1prNxtjAJZZa3d5l5+Kp5jN9i4D6GWM6QV8D7jOWtsMNOMtRt5ZHYCtwFJgkTHmA+ADa+2n+2SZBjxrra3xPn4Q+J0xJsz7+B3vTFeVMaYAz6zU/jThmSUDGA+kA2+2yuwGhnkzv2KtLQew1l63ZwVjzHpjzK+83+/kVttrzzF4ZrSWeLf5OvC6d6arLa3H+WXg/4wxacBReI6ZW2uM+QkHGH9r7c4O5hMRP1P5EpH2fOuYr/2obvW5C3jBWnsTgDHGCfQByvEUnr03k/XOdNXueWytbfHO3IzGU3r+aoz53Fp7bavt7ztb78Tzc8yxJ2urZW7AYYz5OZ7deuA5CP5OoN5a29Qq82pr7d5ZNmNMH6AEz+xZ68wJQAKeEvhTPAfW/xvYiWfXZUfsOw4OPDN1la2+D4Cwfb5u7zhba2uMMa8Al+Apj0+1+l4ONP4i0klot6OI+NL/gIuNMenexz8H9sxefQJcboxxGmPCgVf59m7H4Xh2I6621t4N/BUYvs/2PwKuMMZEex9fA3xlra0/UCBr7ePW2hHejx/vZ5W5wABjzERvjhF4ju3q4818jjEmzrvudOA64CTgn9bafwAWOB1P8emIr4HBxpgjvY/PxLMbsgIIM8Yc4X3+7Ha2s2fX4wTgNe9zbY2/iHQSKl8i4jPW2o/wHLj+sTFmGZ6ZmXOstW7gD3gOpF8KLAbe9+5y2/O1S/HsTltgjFkA/Aj4zT4v8Q88hWieMWY1nl1ulx5m5hLgXOA+Y8xS4AU8x39tsta+j+d4sFnGmOVAGp6TBP4P+Jl3d+ynwCI8u/s68npF3szPeb/+OuAia20lcCPwgTFmPq1mxw6wnYV4ZtFes9bWeZ9ra/xFpJNwuN36NykiIiISKJr5EhEREQkglS8RERGRAFL5EhEREQkglS8RERGRAFL5EhEREQmgLnOR1ZKSqk5xWmZiYhTl5bXtryjt0lj6jsbSdzSWvqOx9C2Np+8EYixTUmIdB1qmma+DFBLS0esoSns0lr6jsfQdjaXvaCx9S+PpO8EeS5UvERERkQBS+RIREREJIJUvERERkQBS+RIREREJIJUvERERkQBS+RIREREJIJUvERERkQDy60VWjTFjgXustZP3ef504HagCXjGWvuUP3OIiIjIdy1atIDbb7+FnJx+ADQ1NXH++RczZcrUg9rOgw/ez4UXXkpaWtp3ls2dO5uioh2ceeY5h5Tx3/9+ntmzZ1JdXU1pacnerA8++Bgu1+Fdr6v19+9wOKivr+fEE0/mvPMu4q67ppOfv4bY2DgAKisruOii73PqqWcc1muCH8uXMeZG4DKgZp/nQ4G/AmO8y2YZY9621hb5K4uIiIjs36hRo/nDH+4GoLa2lquv/inZ2dkMGGA6vI1rr/3tAZeNGzfhsPJdcskPuOSSH7Bo0QLeeuu1vVl9pfX339DQwCWXnMtJJ50KwC9+cc3e/Lt2VXLZZRdwyimn43Ac8OL1HeLPma91wDnAC/s8PxgosNaWAxhjZgITgVf8mKVd1bsb+WrpNkJDnMRHhxEbFUZcdBjx0WFER4Qc9kCLiIh0dlFRUZx55jl8/vmnDBhgePzxR1i6dDEtLS1ceOGlnHDC91i5cgUPPXQ/LS0tpKSkcscdf+K3v72GG264lcrKCh555G+EhIQQERHBnXfewxdffMamTRv5xS9+xUsv/YtPP/0fLpeL4cNHctVV1/CPfzzB9u3bKC8vp6hoO7/61XWMHTu+3az/+McTrFixjN27d3PzzbexYMHXfPzxRzgcDqZMOZHzz7+IoqId3Hvvn6mvryM8PIIbb7yV3r2/Ozu3R21tLU6nc78zamVlZYSFhfukD/itfFlrXzPG5OxnURxQ2epxFRDf3vYSE6P8ejuA/KXbePWLdftd5nI6iI8JJyHW+xETTqL38/gYz+M9y+Kiw3E5VdQ6KiUlNtgRug2Npe9oLH1HY9lxz7yzkllLt/p0m8cMz+BHpx95wOUJCVGEh4d+6+8pJyeDwsJ1rFq1iJ07i3n11Zepr6/nggsuYNq0Kfz1r3/hgQceIC8vj1deeYXKymLCwkJITIzi00/f54wzTuPyyy/ns88+IzS0hdjYCKKiwti5cxszZnzGq6++TEhICL/61a9YsWIB0dHhxMVF8+CDDzBr1iyeeeYZTjvtxHazRkeHM2jQQH7/+99TUFDAV199xiuv/BeAK664gpNPnsLTT/+dK6/8IZMmTWLOnDk8++zj3H///YDnvZmQEMXixQu57rqrcDgchIaGMn36HfTt25uIiFCefPIRXnrpObZt20ZeXh4PP/yQT97Twbix9i6gdfJYoKK9L/L3DTAHpMfw+x+MZueuOiprGthV08CuWu+fNQ1U1jSwpbiK9Vsr29yOwwGxkaHERYd98xHlmUGL886offN5KCGunnvOQ0pKLCUlVcGO0S1oLH1HY+k7GsuDs7u2geZm9wGXu1yONpcfaJtt/R1UVNRSX9/4rXXy8zcQG5vI4sXLWbZsORdeeDEAdXUNrFiRT3FxCXFxqZSUVDF58skANDQ0UV5ey3nnfZ/nn3+GSy75PikpqWRk5FFVVUdtbQNLlqxi4MAjqKioA2DQoCEsWbKC+vp6srJyKSmpIjw8jurq2v1m3jdrTU09KSl9KCmpYsGCZWzZspVLLvk+AFVVVSxbtobVq9ewdeujPPro494xDKGkpGrve7OiopaRI0d9Z1dmSUkVdXWN/PSnVzNu3ATmzJnJY489TFRUrw6/p9sqacEoX6uBAcaYXkA1nl2O/xeEHN/icDjI7RNHbp+4NteLjYtkXeHOvaVsbzmr/fbjsl31bCmpaXNbANERIXt3b+4panHf+TyU+OgwQnVTVRGRbuuCE/pzwQn9D7g8EGW2pqaad955gzvvvIfCwk2MHDmam276HS0tLfzzn0+TkZFJcnIymzcXkpWVzb/+9U+ysvru/fr//e99TjnlNK6++te88MKzvP3266SlpQPQt28O//nPv2hqasLlcrFkyWJOPvlUCgryOdQ9eU7vnqbs7L7k5ORy//0P4XA4+O9/XyQvbwDZ2TlcfPH3GTp0OJs2bWTx4oWH9Drjxx/LihXLuffeu7jzznsOLWwrAStfxphLgBhr7ZPGmOuAj/Bc6uIZa61v51n9KCI8hNSESFITIttdt7GpmV01jeyqbfhmNm2fWbXKmgaqahvZXtb+zF5kuOvb5Sw6jPiofWfUPLNuEWHB6NUiItLVLFy4gKuv/ikul4vm5mauvPJnZGfnkJXVl8WLF3LVVT9m9+5aJk48nqioaG644VbuvvuPOJ1OkpKSuOCCS3jllZcAGDx4CH/5y51ERkbicDi48cbfsWTJIgDy8vpzwgnf4xe/uBK3282wYcOZOHEyBQX5h/09DBgwkNGjx3DVVVfS0NDI4MFHkpKSwi9/eS333/8XGhoaqK+v49prrz/k1/jhD3/MFVdcyuzZM5kw4djDyutwuw9uCjNYSkqqOkVQf/3m0dTcQlVt4353d37z2FPkqmobaO+vLSzU+a3dnd+dVQvdO+MWGR6cEwq0S8J3NJa+o7H0HY2lb2k8fScQY5mSEnvA/1g1PdJJhLicJMZ6DuRvT0uLm+rdjfvd3ekpb9+UuI07qmhuabuphbicnhmzVuXsmzM+Q/fOrsVFhxEdGYpTZ36KiIgcMpWvLsjpdOwtQ5ntrOt2u6mpa/rW7s7Wu0Crahv3Pt5aWsPGHW3/JuByOoiJ+nYh+2ZWLfRbJxjERIXicvbcEwpERET2R+Wrm3M4HMREhhITGUqf5Og213W73dQ1NH+zu3OfXaB7Z9RqGiiq2E1hcXXbrw3ERH27kMW2Kml52b1IiQnViQQiItKjqHzJXg6Hg8jwECLDQ+jdK6rd9esbmw98xmerola+q56tBzjzMyzEyaC+iZx+TA55fdq93JuIiEiXp/Ilhyw81EVKQiQpHTrzs4WqfXZ5ltc2Mn/lDpatK2NrSTV3/2x8j77umYiI9AwqXxIQoSFOesVF0CsuYu9zKSmxnDG+Ly98ZPl88VYeenUZR5kUz7L4SI7s1ytYcUVERPxG5UuC7oRRmSy0xazYsJMVG3buff4npx1Bbp84kuIjNCMmIuJVW1tLUdEOevdOIyqq/UNE2rJo0QJuv/0WcnL6AZ4bS19//c0MHDjooLbz1luvc+qpZxAS8k2t2HfbAFOnnsyZZ54DwMqVK3jssYd45JEnD+t76IpUviToMpKjue+qCaxYv5P6xmb++1kBlTUNPPXuKsBzy6bc9DiOHtybMYNTSYhp/3IcIiLdTVNTE7///U188MF7bN26hYyMTKZNO5Xp0+/6Vuk5WKNGjd57e5158+by9NOPc++9fzuobbzwwrOcfPKp38nRetutvfjic3z00ftERLR/2Ep3pPIlnUJoiIuRAz27HIf3T2ZpQSnFFbspKd/NjvJa1m/bxbptu/jPp2sZkBlPbp94slJjGJAVT3J8z/zHKyI9y/XXX8+TTz629/HmzYV7H/viljcAVVW7SEhIBGDdugL+9rf7cLvdxMfHc8std9DY2Mgdd9xCS0sLDQ0N3HDDLVi7mp07y5g+/Vbuvvv+Dr1ORkYmd911H3/60+37Xf7nP/+BLVs2U19fz/nnX8TJJ5/KrFkzePbZp3C73QwcOIgbbriFhQvn8eSTjxEeHk5cXDy33HI7a9daHnvsYUJDQznjjLPp3TuNJ598FJfLRZ8+Gdx44+98MlaHQ+VLOp3I8BDGHZn2recqaxpYsKaYr1cVkb+lkvwt39zgvF96LKNNKqMGpXbotk8iIl1NbW0tb7755n6XffDB+9x66x2HvAtyz+2FGhsbKSjI31ug7rnnTm655Xb69cvl3Xff5MUXn2Po0OHExcVz221/YMOGDezevZvTTjuLf/7zH0yf/ucDbnuPBx98DJfLxeTJU9i+fdsBvtcalixZxBNP/BOHw8G8eXNpamrir3+9l6eeeo7ExF68+OJzFBcXce+9f+bRR58mJSWVl19+ieee+wcTJhxLQ0MDTz31HG63m4svPpfHHnuaxMRePPXUY7z//jtceeUPDmmsfEXlS7qE+OgwpozKZMqoTGrrmthSUs2mHVUsW1/G6o3lbNhexStfrGPKUZlcOKW/jhETkW6lqGgHmzdv3u+ybdu2UFS0g379cg9p2613DRYWbuRnP/sRb775Pps2beD++/8CQHNzE5mZ2YwbN4EtWwq5+ebfEhISwuWXX9nhbXdUVFQ011zzW+699y5qa2s48cRpVFZWEBsbS2Ki50SsSy+9nPLycqKioklJSQVgxIiRPPHEo0yYcCzZ2Z6bfVdUlFNWVsptt90MQH19PWPGjD2oPP6g8iVdTlRECAOzEhiYlcDUMVlU725kUX4J/5u/mU8XbaGwuIpfnj2UuOiwYEcVEfGJ3r3TyM7OZuPGjd9Z1qdPJr17p333iw5BYmLS3s+zs/vy+9//kbS0NJYtW0JZWSmLFy8kKSmZv/7176xYsYwnnvg7Dz/8BA6HE1/dK7q0tBRrV3P33f9HfX095557KieeOI3q6mp27aokLi6ev/3tPqZOnUZtbQ2lpaUkJyezZMkisrKyAc+dYADi4xNITU3lL395gJiYGGbO/JLIyMM7ScEXVL6ky4uJDGXi8D4cPTiVZ99fw/w1xfz5Xws5dXxfhuYm6QB9EenyoqKiOPPMM3nwwQe/s2zatFMO66zHPbsGXS4XtbU1/OpXvyE8PILf/vYW7rzzdpqbm3E4HNx8823Ex8dzxx238sYbr9Lc3MwVV/wEgOHDR3D99dd4i9jh3f83KSmJnTvL+PnPf4TT6eSii75PaGgo1113Ezfc8GucTicDBxqOOOJIbrzxd/zudzfgdDqIjY3j1luns359wd5tOZ1Orr32em644VrcbjdRUdHcdtsfDiufLzh81VT9raSkqlME1V3lfccfY+l2u3n9q/W8N2fT3uf69o5laF4Sw/KSyE2P2/sbUXei96XvaCx9R2PpW4mJkfzyl9fwwQfvs23bFvr0yWTatFMO+2zHnigQ782UlNgD/mej8nWQ9MPEd/w5ljt21rKsoJRl68uwhRU0t3jePtERIQzJTWLisHQG53Sfi7jqfek7Gkvf0Vj61p7x9OV1vnqqYJcvVWXpltJ6RZF2dDYnHp3N7vom1mwqZ9n6MpatK+PrVUUstMXcdvkYslJjgh1VROSgREVFHfLB9dI56JQw6fYiw0MYOTCFy08exP9dNYFLpw6kqdnNA/9dQknF7mDHExGRHkblS3oUh8PBlFGZXPK9AVTWNHD7M/P4elVRsGOJiEgPovIlPdL3Rmdx9nH9qG9o5tn3V6uAiYhIwKh8SY91+jH9uOqsIeCAJ95eyeNvraCpuSXYsUREpJvTAffSo40elEpW7xiefncV81YXEx0ZymUnmmDHEhGRbkwzX9Lj9U6M4voLR5KZEsPni7Yyc9n2YEcSEZFuTOVLBAgPc3H1OUOICg/h+Y8sazaVBzuSiIh0UypfIl6piVH89IwjaW5u4d6XFvPwa8vYUlwd7FgiItLN6JgvkVaG5SVx06VH8eoX61i8tpQla0sZMziV0SaVgdkJxEXpZt0iInJ4VL5E9jEwK4Fbvn8Uy9fv5I2v1jNvdTHzVhcDkJEczeC+iUwb15fEWN2wW0REDp7Kl8h+OBwOhuUlMTS3FwVbK1mzqRy7uYKCrZVsXVjDrBXbOXdSHpNHZuB0dL8bdYuIiP+ofIm0weFwMCAzgQGZCZwONDW3MGv5dl75fB3/+l8+c1bu4IcnDyIjRfeIFBGRjtEB9yIHIcTlZNKIDO76yVjGDEpl3dZdTH92Pm/P2qALtIqISIeofIkcgviYcH5x1hCuOW8YcdFhvDljA3c+t4DCoqpgRxMRkU5O5UvkMIzon8yfrhzLccPSKSyu5s7nF/D5oi243e5gRxMRkU5K5UvkMEVFhHDFKYP59fnDiQgL4YX/5fP0u6uob2gOdjQREemEVL5EfGRYXhLTrxhDbp845qws4s7nF7C9rCbYsUREpJPR2Y4iPtQrLoKbLz2K/35WwKcLt/DH5xYwLDeJnPRYctLi6Ns7lqgI/bMTEenJ9L+AiI+FuJxcOnUg/TPieenTtcxfU8z8NcV7l/dLj+Xqc4bpIq0iIj2UypeIn4w9ojdHD06lrLKOjTuq2LBjFwVbKlm7pZKn3lnJ9ReNxOnUBVpFRHoalS8RP3I4HCQnRJKcEMnoQam43W4eeX05i9eW8u6cjZxxTL9gRxQRkQDTAfciAeRwOLjilMEkxYXz1swNzFmxg8YmXZxVRKQnUfkSCbCYyFB+duYQnA4HT727il8/PIOn3lnJ4vwSGpt0eQoRke5Oux1FgqB/Rjx3/HAMs1fsYP6aYuasLGLOyiIiwlyM6J/MmMGpDMtLwuXU70ciIt2NypdIkGSmxnDBCf05//g8Nu6oYv6aYhasKWbuqiLmrioiOT6C743Ool96LElxESTEhH/nAP3a2lqKinYQHT0gSN+FiIgcLL+VL2OME3gUGA7UAz+21ha0Wv5b4BKgBfiztfYNf2UR6cwcDgf90uPolx7H+ZM9RWzG0m3MWrGD/3y6du96LqeDxNhwhuUlMWZQCs8/eQ8ffvAeW7duITs7mxNPnMb06XcREqLfqUREOjN//pQ+C4iw1o43xowD7gfOBDDGJADXAv2BaGAJoPIlPV7rInbWxFwW2RJKKnZTtquOsl117Cir5bNFW/ls0VZqmoYTmVVJZNXnbNy4kSeffAyAO++8J8jfhYiItMWf5etY4EMAa+1cY8zoVstqgE14ilc0ntkvEWklLiqMySMzvvVcU3MLi+12/vzwv4hNH8LAcReQN/os5r3xJ8o2L+eDD97n1lvvICoqKkipRUSkPf48mjcOqGz1uNkY07rsbQZWAYuAh/yYQ6TbCHE5SY6sZ84bd/Px4z9k1Vf/xOkKYey508kbcy7btm+jqGhHsGOKiEgb/DnztQuIbfXYaa1t8n4+DUgH9lxh8iNjzCxr7bwDbSwxMYqQEJd/kh6klJTY9leSDtFYHrzo6AFkZ2ezceNG1i94k8qiAkZO+w2Dj7uMLDOWPtlZGtfDpPHzHY2lb2k8fSeYY+nP8jULOB142XvM1/JWy8qB3UC9tdZtjKkAEtraWHl5rZ9iHpyUlFhKSqqCHaNb0FgeuhNPnLb3GK+yzSv48vlfM/zEq0nrP5YbHpnLj04ZzIgByUFO2TXpfek7Gkvf0nj6TiDGsq1y58/djm8AdcaY2cBfgd8YY64zxpxhrZ0BzAfmGmPmAPnAx37MItKtTJ9+Fz/96S/IyuqLy+UiIy2JkWkVXDylP3UNzTz02jJe/DhfF20VEemEHG63O9gZOqSkpKpTBNVvHr6jsTx8e67zNWTIAGpqPEVrc3E1T7y9km2lNWSmxPDj0waT3Vu7KjpK70vf0Vj6lsbTdwI08+U40DJdPlukC4uKiqJfv9xvnd2YlRrDbZePZvKIPmwpqWb6s/N59I3lbC6uDmJSERHZQ1djFOmGwkNd/ODkQYwcmMIbX61ngS1hgS3hqIEpnHx0Nn2So4mK0D9/EZFg0E9fkW5saG4SQ/r1Yvn6Mt6auZFF+SUsyi8BIDYqlPMm53Hs0HQcjgPOjouIiI+pfIl0cw6Hg2F5yQzNTWLlhp0sWlvKzl11rN1SwbPvr2Hlhp384CRDVERosKOKiPQIKl8iPYTD4WBIbhJDcpMAKK3YzRPvrGTe6mLWbd3Fr88fRkZKTJBTioh0fzrgXqSHSk6I5OZLj+K0CTmU7arjnn8vprBIZ1KJiPibypdID+ZyOjlnYi4/ONlQvbuR+15azKYdKmAiIv6k8iUiTB6RwRWnDKK2ron7XlrMhu27gh1JRKTbUvkSEQCOG9aHH592BLsbmrj3pcV8unALG3fsor5BV8kXEfElHXAvInuNH5JGWKiTp99dzYsf5+99Pikugj7J0aQnRdEnOZrMlBj6pcfqEhUiIodA5UtEvmWUSSW7dywr1pexrbSWbWU1bCurYfn6MpavL9u7XnbvGM46LpfheUkqYSIiB0HlS0S+IyUhkuOPyvzWczV1jWz3lrGVG3ayYE0xD726jH7pcZx9XD+O7NdLJUxEpANUvkSkQ6IjQumfGU//zHgmDvfcN/KtmRtYaEt44OWl9M+M5+xj+zE4p1ewo4qIdGoqXyJySDJTYvjl2UMpLKrizRkbWFJQyn3/WcKg7ATOOi6XgVkJwY4oItIpqXyJyGHJ7h3LNecNY8P2Xbw5YwPL15fxlxcXcWS/Xpw+IYcBmfHaHSki0orKl4j4RL/0OH5zwXAKtlTy5sz1rNywk5UbdpLdO4bvjcpi3JG9CXHp6jYiIipfIuJT/TPjuf6ikeRvruDj+ZtZtLaEZ95fzVszN3Dq+L4cMzSd0BCVMBHpuVS+RMQvBmYlMDArgbLKOj6aV8iXS7fx/EeWd2Zv5JRxfZk4PJ3QEFewY4qIBJx+/RQRv0qKj+CSqQO55+fjOXFMFjW7G3nx43xuenwOHy/YTEOjrqAvIj2LypeIBERCTDgXTRnAvb+YwLSx2eyub+alT9Zy4+Nz+GheoW5jJCI9hsqXiARUXHQY5x/fn3t/MZ5Tx/elobGZ/35WwI2Pz2b1pvJgxxMR8TuVLxEJitioMM6dlMe9v5jAGcfksLu+ib+/vpztZTXBjiYi4lcqXyISVDGRoZx1XC4/nDaI2vomHnp1GdW7G4MdS0TEb1S+RKRTmDAknVPG9aWofDePvbmCpuaWYEcSEfELlS8R6TTOmZTLyAHJrN5Uzr8/WYvb7Q52JBERn9N1vkSk03A6HPzk9CO4+1+L+GLxVmxhOVmpMWSlxpCZ4vkzMTZctysSkS5N5UtEOpWIsBCuOXcY//xwDeu3VbK9rJZ5q4v3Lu+THM1FJ/RnSG5SEFOKiBw6lS8R6XSS4iP47YUjcLvdlFXWsbmkmi3F1WzcUcWSglIeeHkpw/KSuGjKANJ6RQU7rojIQVH5EpFOy+FwkJwQSXJCJCMHpABQWFTFfz5dy7J1ZazcsJMpozI545gcoiJCg5xWRKRjdMC9iHQp2b1jueHikfzy7CEkxobzv/mbufmJuXyxeCstLTpAX0Q6P818iUiX43A4GGVSGZaXxP/mb+bd2Zt4/iPLxws2c/zIDCYMSdNMmIh0WipfItJlhYa4OHV8DscMTef1L9czZ+UO/v3JWl79Yh1jBqUyaUQGeRlxOjtSRDoVlS8R6fISYsL50amDOXdyHrOWb+erJduYtWIHs1bsICM5mokj+jBhSBrRmg0TkU5A5UtEuo346DBOGdeXk8dms2ZTOV8u2cai/BJe+mQtL39WQEZKNDlpsYwZ3Jsjc3oFO66I9FAqXyLS7TgdDo7I6cUROb3YVdPArBXbWbCmhM3F1RQWVfPV0u2MPaI3F00ZQHx0WLDjikgPo/IlIt1aXHQY08b2ZdrYvjQ1t7BxexUvfbqWr1cVsXxdGecfn8dxw/vg1HFhIhIgutSEiPQYIS4n/TPj+d1lo7h06kBa3G6e+9Byz4uL2FpaE+x4ItJDaOZLRHocp9PBlFGZHDUwhRc/zmdRfgnTn5nHxOF9OOW4XJKidGC+iPiPZr5EpMdKjA3n6nOG8qtzhhIXHcbni7dy0yMz+WLJ1mBHE5FuTDNfItLjjRyYwpDcJFZt3MmzH6zh+Q8tazaVM6RfEgOzE0iJj9C1wkTEZ1S+RESA0BAnw/snc981x3HHE3OYt7qYeauLAUiKC8dkJ2KyExicnUhyQmSQ04pIV6byJSLSSp/kGO788Vg2F1eTv6WC/M0V2MIKZq/YwewVOwBIiotgUN8EBmUnMig7kaT4iCCnFpGuxG/lyxjjBB4FhgP1wI+ttQWtlk8D7gAcwELgl9Za3RVXRILO6XTQNy2WvmmxTB2dRYvbzbaSGlYXlmMLK7CF5cxavoNZyz1lLDk+gkHZiQzum8hRA1MID3MF+TsQkc7MnzNfZwER1trxxphxwP3AmQDGmFjgPmCytbbUGHMjkAyU+DGPiMghcTocZKbGkJkas7eMbSmuZo23iNnCCmYu387M5duJiQxl6uhMThiVqdsZich++bN8HQt8CGCtnWuMGd1q2QRgOXC/MSYXeNpaq+IlIl2C0+Egu3cs2b1jOXFMFi0tbjYXV7Mwv4TPFm7hjRkb+ODrQo4fmcHUMVkkxIQHO7KIdCIOt9s/e/qMMU8Dr1lrP/A+LgRyrbVNxphL8cyEjQCqgRnAhdba/ANtr6mp2R0Soql8Eencausa+XDOJt78soDyqnqcDhjaP5ljhmcwYWg68SpiIj3FAU+R9ufM1y4gttVjp7W2yft5GTDfWrsDwBjzFZ4idsDyVV5e66eYByclJZaSkqpgx+gWNJa+o7H0HV+M5XFDejNuUDKzVuxg1vLtLF1bytK1pTz22lIGZScyZnAqRw1MIS6qe99XUu9L39J4+k4gxjIlJfaAy/xZvmYBpwMve4/5Wt5q2SJgiDEmGagAxgFP+TGLiEhAhYa4mDwig8kjMiirrGOBLWbBmmJWbypn9aZy/vVRPoP6JjDKpDKifzKJsZoRE+kp/Fm+3gCmGmNm45l6u8IYcx1QYK192xhzC/CRd92XrbUr/JhFRCRokuIjOOnobE46OntvEZu/pphVG8tZtbGcFz6y5KTFMmJAMiP6J5OVGqOLuop0Y3475svXSkqqOkVQTfv6jsbSdzSWvhPIsSyt3M3itaUsWVtK/uYKmls8P+aS4iI8RWxAMiYrgRBX17wTnN6XvqXx9J0A7XY8vGO+jDF9gauBXrQ6gMxa+6PDTici0kMlx0cydXQWU0dnUVvXyPL1O1lSUMqydWV8unALny7cQmS4i6G5SYzon8zQvCRdvkKkG+jobseX8ZyROAPoFDNQIiLdSVREKGOP6M3YI3rT1NzC2s0VLC7wzIrtudWR0+FgYFY8IwakMGJAMqm6zZFIl9TR8hVqrb3er0lERASAEJeTwTm9GJzTi4unDGBraQ1L1paypKCUNYUVrCms4D+frqVvWixnHtOP4f2TdIyYSBfS0fI10xhzOvCRtbbBn4FEROQbDoeDzJQYMlNiOG1CDhXV9SxbV8ai/BKWryvjodeWkZcRx7kT8xjUNzHYcUWkAzpavs7Dc8wXxpg9z7mttbrqqYhIACXEhDNxeB8mDu/D1pJq3pixgUX5Jdz70mIGZMbTPzOejORoMpJjSE+KIixUP6ZFOpsOlS9rbR9/BxERkYOTkRLD1ecMZcP2Xbz+5TpWbixn7ZbKvcsdDkhJiPSUsZQY+vaOpV96LImx4dpNKRJEHT3bMQq4A5ji/ZrPgNustTV+zCYiIh3QLz2O3140kqraBraV1rC1tIatJXv+rGbx2lIWry3du35cVCg56XHkpMWSkxZHTnqs7j8pEkAd3e34CFAL/AjPpSZ+AjwOXOanXCIicpBio8Iw2WGY7G+O/XK73eyqaWBzSTWbdlSxcXsVG3fsYtm6MpatK9u7Xr/0OCYMSWPsEb2JidTlLET8qaPla5S1dnirx1cbY1b5I5CIiPiOw+EgPiac+JhwhvRL2vv8rtoGbxnbRf7mClZtKmfD9l3859O1DO+fzIQhaQzLS+qyF3gV6cw6Wr6cxpgEa20FgDEmAWhq8ytERKTTiosKY2huEkNzPYWsorqeuSuLmL1iO4vyS1iUX0JMZChHD07lmKHp5KTF6jgxER/paPl6AJhvjHkbz27H04G7/ZZKREQCKiEmnJPHZnPS0VlsLq5m9oodzF25g88WbeWzRVtJT4piwpA0xgzuTUp8hIqYyGHo8L0djTFDgEmAE/jCWrvcn8H2pXs7dj8aS9/RWPqOxvIbzS0trNywk9krdrAov5Sm5hYAesWFMzAzgYFZno/0pKj9ljGNpW9pPH2nU9/b0RhzmrX2XWPMD7xP7Uk60hgz0lr7vK9CiohI5+JyOhmWl8ywvGRq6xqZv6aYFet3YjdXMHdVEXNXFQEQExm6t4gNzIonKzUGl1PHiokcSHu7HccA7wLH72eZG1D5EhHpAaIiQpk0IoNJIzJwu91sL6slf0sF+Zs9H3uOEwOICPPcDPyn5wxDl3gV+a4O73bcwxgTD2Raa1f6J9L+abdj96Ox9B2Npe9oLA9NaeVubxGrxBaWU1S+m7BQF6eN78vJY7N11qQP6L3pO516t+MexpgrgWOAm4DFQJUx5jVr7e99E1FERLqy5PhIkuMjmTAkHbfbzderinj5i3W8/tV65qzcwfdPNAzWvSdFAM/B8x1xFXA9cDHwFjAUONlfoUREpOtyOByMOzKNx26awglHZbCjrJb7XlrMU++spLKmIdjxRIKuw/PA1tqdwCnAe9baJiDSb6lERKTLi4kM5fsnGn5/+Wj6psUyZ2URv3tyLp8v2kJjU0uw44kETUev87XSGPMukAt8Yox5GVjgv1giItJd9EuP47YfjObzxVt5/at1vPC/fP7zWQF5feIw2YmYrATyMuIIDdHh+dIzdLR8/QiYAKyw1jYYY14A3vdfLBER6U6cTgdTRmUy2qTw4bxCVm8sxxZWsKawAoAQl5PcPnEMyk7gqIEpZKXG6EKu0m21d52vn1prnwRu9T412RizZ/FI4I9+zCYiIt1MfEw4F54wAICaukbyN1dgCz0fa72XrXh71kZ6J0YyZnAqo02qiph0O+3NfDn2+VNERMQnoiNCGTkghZEDUgCorWtk1cZy5q8pZum6Ut6dvYl3Z2+id68oRpsUhvTrRW6feEJDdNkK6draLF/W2ie8n94FnGKtfdsYkwycATzr73AiItJzREWEMnpQKqMHpVLf0Myy9WXMX1PMsoJS3puziffmbMLpcNC7VyR9kqIZlpfEMcPScWpWTLqYjh7z9STgAt72Pj4eOBr4uT9CiYhIzxYe5mLMoFTGeIvY6k3lrNywk01FVWwtrWF7WS0L80v4YslWLjvJkJMWF+zIIh3W0fI1xlo7FMBaWwpcZoxZ5r9YIiIiHuFhLkYMSGbEgGQA3G43JZV1vPHVer5eVcSf/rmAySMzOGdSLtERoUFOK9K+jpYvpzEm3Vq7HcAYkwroIi0iIhJwDoeD1IRIfnbGkUwcls6/Ps7n88VbmbNyB+lJ0aQmRpKSEEFKQiSpCZGkJESSEBuu3ZPSaXS0fN0FLDbGzMRz8P3RwLV+SyUiItIBg3N68YcfHc3H8zfz1bLtFBZVsWH7ru+sF+JykBwf6Slm8d5ylugpZinxkYSH6RpjEjgdKl/W2n8bY74AxgONwNV7ZsFERESCKcTlZNq4vkwb15eWFjc7q+ooqaijpGL33o/ics+fO3bW7ncb8dFhniKW8M2sWa/YcCIjQogMCyEyPITIcBchLqcueyGHraM31g4DfggMAn4FXGuM+Yu1VjfpEhGRTsPpdOy9yff+buRdW9e4t5gV71PM1m/bRcHWyja373I6iAwPITzUSW19EyYrkR+dOpiYSB1rJh3X0d2OfwdKgKPwzHz1B/4BXOanXCIiIj4XFRFK37RQ+qbFfmdZU3MLO3d5Zs2KK3ZTWV1PXUMztfVN1NU3sbuhee+f20trcANLCkq59sEZ5KTHcmS/JI4blk5Kgm59LG3raPkaZa09yhgzzVpba4y5HFjuz2AiIiKBFOJykpoYRWpiFEd2YP0tJdUsWVvKig07yd9cwYbtVbw7eyPHDks/4PZPOCqDzJQY3waXLqej5cvt3fXo9j5ObvW5iIhIj5OZEkNmSgynTcjhq6Xb+OcHawCYuezAh0Qvzi/htstH0ysuIlAxpRPqaPn6G/AJkGaM+RtwNvAHP2USERHpUiYO78OQfr1oaj7wVZjmrynmtS/X8/Dry7n50qMID9UZlj1VR8vXB8BCPFe2dwGnW2t1kVURERGv9mazThnXl6Kdu5m5fDt3Pb+A8UemMWpQKqk6RqzH6Wj5mmGtHQys8mcYERGR7srhcHDZSYaGpmYWrCnhlS/W8coX6+jbO5bRg1IYMyiV1MSoYMeUAOho+VpqjPkB8DWwe8+T1tpCv6QSERHphkJDnPz8zCFUn9jI4vwS5ttiVm8sZ1NRFa99uZ4pR2Vy8dQBuhp/N9fR8jUWz1XtW78b3ECuzxOJiIh0czGRoRw3vA/HDe9D9e5GFq8t4X/zNvPpoi3UNzVz+ckGl9MZ7JjiJ22WL2NMH+ARoAaYCdxsra0IQC4REZEeISYylOOG9WHkgBQe+O8SZi7bTuGOKi6fNoh+6XHBjid+0F6tfhZYA1wPhAMP+D2RiIhIDxQTGcoNF4/k2GHpFBZXc+fzC/j3J/nsrm8KdjTxsfZ2O2ZYa08CMMZ8CizxeyIREZEeKjI8hB+dMpjxR6bx/Idr+GTBFhbll3D04N4Mzk0iOtRFiMtBeKiLhNhwXa6ii2qvfO29d6O1ttEYo3s5ioiI+Nngvon88cqjeXf2Jt6fu4kPvy7kw6+/e45bdEQIEWEuMlNiuHDKANJ66WzJrqCjB9zv0eGr2htjnMCjwHCgHvixtbZgP+u8B7xlrX38ILOIiIh0W6EhLs6emMtJR2expaSGyrom1hWW09Lipq6hmfLqesqr6tlWWkPZrnqWrivjiJxEEmPCSYwLZ8KQdJWxTqq98nWkMWZ9q8cZ3scOwG2tbetsx7OACGvteGPMOOB+4Mx91rkT+O5t50VERATw3Ax8YFYCKSmxlAxI/s7yL5Zs5fUv19Pc4mbVxvK9z3+2cCu/OncoJlv/zXY27ZWvgYex7WOBDwGstXONMaNbLzTGnAe07FlHREREDt7kERlMHpEBQENjMxXV9azaWM6LH+dz/3+X8tPTj2D0oNQgp5TW2ixf1tpNh7HtOKCy1eNmY0yItbbJGDMEuAQ4D7j9MF5DREREvMJCXaQmRpGaGEVyQgR/f2MFj725grMn5jJ1dBbhYTpAvzNwuN0dPozroBhjHgDmWmtf9j7eYq3N9H5+LzAJz9Xyc/Ac2H+NtfaAs2BNTc3ukBC9aURERDqqYEsFf3h6LhVV9cRFh3HGxFxOPSaXmMjQYEfrCQ54mwJ/lq9z8dyA+4feY77usNZO289604Ed7R1wX1JS5Z+gByklJZaSkqpgx+gWNJa+o7H0HY2l72gsfetQx7N6dyOfLNjMJwu2UFvfRESYi3Mm5vK90Vl+SNk1BOK9mZISe8Dy5c97F7wB1BljZgN/BX5jjLnOGHOGH19TREREWomJDOWs43K576oJnH98HiEuJy99upaSit3tf7H4xcFeaqLDrLUtwM/3eXrNftab7q8MIiIi4hEZHsK0sX1JiAnnqXdW8e+P8/n5mUN0HFgQ+K18iYiISOczZlAqXy7eytJ1Zfzyr18RGuok1OUkzPtnaIiL0BAn8dFhnHR0li5V4QcqXyIiIj1IiMvJ9ReP5K2ZG7CFFTQ2tdDQ1ExjUwt1Dc1U1TbS0NTChuYWlhSUMiwvifMm5ZGZGhPs6N2GypeIiEgPE+Jycu6kvDbX2bB9F698XsCydWUsX1fGhCFpnDc5j/iY8ACl7L78ecC9iIiIdFH90uO44eKR/Pr84WSkRDNrxQ4eem05/rpKQk+i8iUiIiL75XA4GJaXxPQrjmbUwBQ2bN/F/DXFwY7V5al8iYiISJucTgfnH5+Hy+ngtS/X0djUEuxIXZrKl4iIiLQrNTGK40dmUFJRxxeLtwY7Tpem8iUiIiIdcvoxOUSGu3h71gZq6xqDHafLUvkSERGRDomNCuOUcX2pqWvivbmbgh2ny1L5EhERkQ6bOjqLxNhwPp6/hbLKumDH6ZJUvkRERKTDwkI9N+Zuam7hjRnrgx2nS1L5EhERkYMy/sg0slJjmLNiB4VFVcGO0+WofImIiMhB2XPpCTfwyucFwY7T5ah8iYiIyEEb0i+JI/v1YuXGclasLwt2nC5F5UtEREQOyfmT83AAL3++jpYW3Xaoo1S+RERE5JBk945lwpA0tpRUM3vFjmDH6TJUvkREROSQnT0xl9AQJ2/MWE9DY3Ow43QJKl8iIiJyyHrFRTB1dBblVfV8vGBzsON0CSpfIiIiclhOGdeXmMhQ3puziV21DcGO0+mpfImIiMhhiYoI4fRjcqhraOadWRuDHafTU/kSERGRw3b8yAxSEyL5YvFWisprgx2nU1P5EhERkcMW4nJy7uQ8mlvcvPbFumDH6dRUvkRERMQnRpsUcvvEscCWsG5rZbDjdFoqXyIiIuITDoeDC47vD8B/Py/A7daFV/dH5UtERER8ZmBWAiMHJFOwpZLFa0uDHadTUvkSERERnzpvch5Oh4NXvlhHU3NLsON0OipfIiIi4lPpSdFMGtGHop21zFi6LdhxOh2VLxEREfG5M47tR3iYi7dmbmB3fVOw43QqKl8iIiLic/HRYUwbm82u2kY++Low2HE6FZUvERER8YuTxmQTHxPG/+YVUl5VH+w4nYbKl4iIiPhFeJiLs4/LpaGphTdnrA92nE5D5UtERET85pihafRJjmbm8u1sKakOdpxOQeVLRERE/MbldHL+5DzcbnhVtx0CVL5ERETEz4blJTEoO4Fl68pYvXFnsOMEncqXiIiI+JXD4eCCEzy3HXr583W09PDbDql8iYiIiN/lpMUx7ojebCqqYt6qomDHCSqVLxEREQmIcybmEuJy8NqX62lsag52nKBR+RIREZGASE6IZMqoTMp21fHpwq3BjhM0Kl8iIiISMKeOzyEqPIR3Z2+kendjsOMEhcqXiIiIBExMZCinTcihtr6J9+ZsDHacoFD5EhERkYCaMiqDpLgIPl24hZKK3cGOE3AqXyIiIhJQoSEuzp2US1Ozmze+6nm3HQrx14aNMU7gUWA4UA/82Fpb0Gr5b4CLvA/ft9b+wV9ZREREpHM5+ojefDRvM3NXFTF1TBb90uOCHSlg/DnzdRYQYa0dD9wM3L9ngTEmF7gUmACMA040xgzzYxYRERHpRJytLrz6yucFuHvQhVf9Wb6OBT4EsNbOBUa3WrYZONla22ytdQOhQJ0fs4iIiEgnM7hvIsPyklhTWMGydWXBjhMwDn81TWPM08Br1toPvI8LgVxrbVOrdRzAfUCstfZnbW2vqanZHRLi8ktWERERCY5N23dxzf2fk5Eay8O/nYzL1W0OR3ccaIHfjvkCdgGxrR479yleEcAzQBVwVXsbKy+v9XnAQ5GSEktJSVWwY3QLGkvf0Vj6jsbSdzSWvtVdxzMqxMExQ9OZsWw7b36+lonD+/j9NQMxlikpsQdc5s96OQs4BcAYMw5YvmeBd8brLWCptfZn1tqee48BERGRHu6s43IJC3Hyxoz11Dd0/0rgz5mvN4CpxpjZeKberjDGXAcUAC5gEhBujJnmXf8Wa+0cP+YRERGRTigxNpwTj87m3dkb+Wh+IWcc0y/YkfzKb+XLWtsC/Hyfp9e0+jzCX68tIiIiXcu0sdl8uWQrH3xdyKQRGcRHhwU7kt90m6PaREREpOuKDA/hzGP7Ud/QzNszNwQ7jl+pfImIiEinMHF4H3r3iuLLJdvYXlYT7Dh+o/IlIiIinUKIy8l5k/Jocbt59Yt1wY7jNypfIiIi0mkcNTCZ/pnxLF5bSv7mimDH8QuVLxEREek0HA4HFx7fvW87pPIlIiIinUpeRjyjTQrrtu1igS0JdhyfU/kSERGRTufcyXm4nA5e+2IdTc0twY7jUypfIiIi0un0Toxi8sgMiit28/nircGO41MqXyIiItIpnX5MDpHhLt6ZtZHauqb2v6CLUPkSERGRTikuKoxTxvWlencj78/dFOw4PqPyJSIiIp3W1NFZJMaG8/GCzezcVRfsOD6h8iUiIiKdVlioi7OPy6WxqYU3vlof7Dg+ofIlIiIindqEIWlkpsQwe8UOCouqgh3nsKl8iYiISKfmdDq44Pg83MAr3eC2QypfIiIi0ukNyU3iyJxEVm7YyYoNZcGOc1hUvkRERKRLOP/4/jiAVz5fR0tL173tkMqXiIiIdAnZvWMZPySNzcXVzFm5I9hxDpnKl4iIiHQZZx+XS4jLyRsz1tPQ2BzsOIdE5UtERES6jKT4CKaOyWTnrno+Wbgl2HEOicqXiIiIdCmnjutLTGQo783ZSFVtQ7DjHDSVLxEREelSoiJCOX1CDrvrm3ln9sZgxzloKl8iIiLS5Rx/VAYpCRF8vmgrxeW1wY5zUFS+REREpMsJcTk5d1IezS1uXvuya912SOVLREREuqQxg1Lplx7H/DXFrNtWGew4HabyJSIiIl2Sw+HgwhP6A/DKZwW43V3jwqsqXyIiItJlDcxKYOSAZPK3VLJkbWmw43SIypeIiIh0aedNzsPpcPDKF+tobmkJdpx2qXyJiIhIl5aeFM3EEX3YsbOWr5ZuD3acdql8iYiISJd35jE5hIe6eGvGenbXNwU7TptUvkRERKTLi48JZ9rYbHbVNvLRvMJgx2mTypeIiIh0CycenUV8dBgfziukoro+2HEOSOVLREREuoWIsBDOOq4fDY0tvDljQ7DjHJDKl4iIiHQbxw5LJz0pihnLtrG1pDrYcfZL5UtERES6DZfTyfnH98fthle/WBfsOPul8iUiIiLdyvC8JExWAkvXlbFmU3mw43yHypeIiIh0Kw6Hgwu8tx16+fMCWjrZbYdUvkRERKTb6Zcex9GDU9m4o4p5q4uCHedbVL5ERESkWzp3Uh4up4PXv1xPY1Pnue2QypeIiIh0SykJkUwZlUlpZR2fLdoS7Dh7qXyJiIhIt3XahByiwkN4d/ZGauoagx0HUPkSERGRbiwmMpTTJuRQU9fEe7M3BTsOACH+2rAxxgk8CgwH6oEfW2sLWi3/CfAzoAm401r7rr+yiIiISM81ZVQGny7cwicLN3PCURmkpMQGNY8/Z77OAiKsteOBm4H79ywwxqQB1wDHACcBdxtjwv2YRURERHqo0BAX50zKpanZzesz1gc7jl/L17HAhwDW2rnA6FbLjgZmWWvrrbWVQAEwzI9ZREREpAcbe0Rv+vaOZe7KIgq2VAQ1i992OwJxQGWrx83GmBBrbdN+llUB8W1tLDExipAQl+9THoJgT1d2JxpL39FY+o7G0nc0lr6l8Tw8Pzl7KL9/fDYLVhdx0VQTtBz+LF+7gNbvEqe3eO1vWSxQ0dbGystrfRruUKWkxFJSUhXsGN2CxtJ3NJa+o7H0HY2lb2k8D1+fhAimXzGGIwak+n0s2yrK/tztOAs4BcAYMw5Y3mrZPOA4Y0yEMSYeGAys8GMWEREREbJ7xxIZ7s+5p/b589XfAKYaY2YDDuAKY8x1QIG19m1jzEPADDwF8HfW2jo/ZhERERHpFPxWvqy1LcDP93l6TavlTwFP+ev1RURERDojXWRVREREJIBUvkREREQCSOVLREREJIBUvkREREQCSOVLREREJIBUvkREREQCSOVLREREJIBUvkREREQCyOF2u4OdQURERKTH0MyXiIiISACpfImIiIgEkMqXiIiISACpfImIiIgEkMqXiIiISACpfImIiIgEUEiwA3RGxhgn8CgwHKgHfmytLdjPOu8Bb1lrHw98yq6hvbE0xjwIHAtUeZ8601pbGfCgXUAHxnIacAfgABYCv7TW6loyB9DWeBpjRgB/a7X6OOAsa+2HAY7ZJXTgvflb4BKgBfiztfaNoATtAjowljcBFwO7gHutte8GJWgXYowZC9xjrZ28z/OnA7cDTcAz1tqnApVJM1/7dxYQYa0dD9wM3L+fde4EEgMZqos6i7bHchRwkrV2svdDxevAzuIAY2mMiQXuA06z1o4FNgLJQcjYlZzFAcbTWrtkz3sS+DvwmopXm87iwO/NBOBaYDxwIt8utfJdZ3HgsRyKp8SOwzOWfzTGRAUjZFdhjLkReBqI2Of5UOCveMZxEvBTY0zvQOVS+dq/Y4EPAay1c4HRrRcaY87D8xucfhi374Bj6f0NbwDwpDFmljHmR8GJ2GW09b6cACwH7jfGzACKrLUlgY/YpbT57xzAGBMN/AFPeZADa2ssa4BNQLT3oyXg6bqWtsZyMPCFtbbOWlsHrAWGBT5il7IOOGc/zw8GCqy15dbaBmAmMDFQoVS+9i8OaD0D02yMCQEwxgzB85vH7cEI1gUdcCzx/CB+GPg+cDJwlTFGP0gOrK2xTAaOB24CpgG/NsYMDHC+rqat8dzjSuAVa21p4GJ1Se2N5WZgFbAIeCiQwbqgtsZyOTDRGBNrjEnC80tXdKADdiXW2teAxv0s2necq4D4gIRC5etAdgGxrR47rbVN3s9/AGQAnwE/BK4zxpwc2HhdSltjWQs8aK2ttdZW4RnT4YEO2IW0NZZlwHxr7Q5rbTXwFTAiwPm6mrbGc49L8eyykLa1NZbTgHSgH5ANnGWMOTrA+bqSA46ltXY18AiembFHgK8B/WJwaPYd51igIlAvrvK1f7OAUwCMMePw/LYBgLX2RmvtWO+xIP8EHtCxIG064FgCA4FZxhiXd//7sXh+M5b9a2ssFwFDjDHJ3t+Sx+GZaZADa2s8McbEA+HW2s1ByNbVtDWW5cBuoN67q6wCSAhwvq7kgGNpjEkBYq21xwA/B7KAFcEI2Q2sBgYYY3oZY8Lw7HKcE6gX19mO+/cGMNUYMxvPmWNXGGOuw7N/+O3gRuty2hxLY8wLwFw808LPW2tXBjFrZ9feWN4CfORd92VrrX4ot629f+cD8Zy4IO1r7735PWCuMaYFz7E1Hwcxa2d3wLEE3gEGG2PmAw3ADdba5uBF7XqMMZcAMdbaJ73j+hGeiahnrLVbA5XD4XbrTHQRERGRQNFuRxEREZEAUvkSERERCSCVLxEREZEAUvkSERERCSCVLxEREZEA0qUmRKRbMMbkAPl8c30zJ56rWD9nrb3DR68xHcBaO90Y47bWOnyxXRHpWVS+RKQ72WatHbHngTGmD7DWGPMf79XBRUSCTuVLRLqzdDwXqqwyxtwMXAC48FxY8SZrrdsY8xs8VwtvBt6x1t7kvYfrw0AMkArcb63VPQlFxCdUvkSkO+ljjFkCROC52fh84GxgCDAKGAO4gReAS40x+cBVwGigBvjQGDMKuAy401r7qTEmF1iKbggtIj6i8iUi3ck2a+0IY4wTuB8YhueG7XcDY4GF3vUigUIgDc9sV6X3+e8BeAvcyd5bNg3DMwMmIuITOttRRLoda20LcAPQG7gez67Gv1lrR3iPCRsL3IXnnqJ7GWP6GGMSgJfxzJitAm4NXHIR6QlUvkSkW7LWNuEpXrcCi4DLjDExxpgQ4E3gPGAGMK3V8y/h2QU5FbjdWvsWMAnAGOMK/HchIt2RypeIdFvW2g+BuXgK1GvA18AKYAmeS1AsAh4B5uA5rusra+0nwHRgpjFmEXASsBHoF+D4ItJNOdxud7AziIiIiPQYmvkSERERCSCVLxEREZEAUvkSERERCSCVLxEREZEAUvkSERERCSCVLxEREZEAUvkSERERCSCVLxEREZEA+n+XED/8H4b7TQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Вычисляем F1-score при различных threshold\n",
    "f1_scores = (2 * precision * recall) / (precision + recall)\n",
    "#Определяем индекс максимума\n",
    "idx = np.argmax(f1_scores)\n",
    "print('Best threshold = {:.2f}, F1-Score = {:.2f}'.format(thresholds[idx], f1_scores[idx]))\n",
    " \n",
    "#Строим PR-кривую\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) #фигура + координатная плоскость\n",
    "#Строим линейный график зависимости precision от recall\n",
    "ax.plot(precision, recall, label='Decision Tree PR')\n",
    "#Отмечаем точку максимума F1\n",
    "ax.scatter(precision[idx], recall[idx], marker='o', color='black', label='Best F1 score')\n",
    "#Даём графику название и подписываем оси\n",
    "ax.set_title('Precision-recall curve')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "#Отображаем легенду\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, согласно нашим вычислениям и построенной PR-кривой, максимум  (0.69) на кросс-валидации наблюдается при пороге вероятности 0.33.\n",
    "\n",
    "Сделаем предсказание классов с таким порогом для всех объектов из отложенной валидационной выборки и выведем отчёт о метриках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76       400\n",
      "           1       0.62      0.76      0.68       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.72      0.73      0.72       656\n",
      "weighted avg       0.74      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Образцы воды, для которых вероятность быть пригодными для питья > threshold_opt, относим к классу 1\n",
    "#В противном случае — к классу 0\n",
    "y_valid_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "y_valid_pred = (y_valid_pred_proba > 0.33).astype('int') # Best threshold = 0.33 (threshold_opt)\n",
    "#Считаем метрики\n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, при применении метода подбора вероятности увеличилось значение метрик recall и  для класса 1. Нам удалось сократить разницу метрик между классами и заставить модель практически одинаково хорошо предсказывать классы питьевой и непитьевой воды.\n",
    "\n",
    "Примечание. Чтобы вычислить площадь под PR-кривой, используется функция auc() из модуля metrics библиотеки sklearn. В данную функцию нужно передать значения метрик recall и precision при различных порогах вероятности:\n",
    "\n",
    "print('PR AUC: {:.2f}'.format(metrics.auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('PR AUC: {:.2f}'.format(metrics.auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СЭМПЛИРОВАНИЕ\n",
    "\n",
    "Следующий подход работы в условиях дисбаланса классов, который мы рассмотрим, — сэмплирование, а точнее — пересэмплирование (oversampling).\n",
    "\n",
    "Идея очень проста: если у нас мало наблюдений миноритарного класса, следует искусственно увеличить их количество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "алгоритм SMOTE (Synthetic Minority Oversampling Techniques).\n",
    "\n",
    "В основе алгоритма лежит идея генерации некоторого количества искусственных наблюдений, которые были бы «похожи» на наблюдения, имеющиеся в миноритарном классе, но при этом не дублировали их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмов сэмплирования, в том числе SMOTE, нет в стандартном пакете sklearn — \n",
    "они содержатся в библиотеке imblearn (imbalanced-learn). \n",
    "Команды для установки приведены далее.\n",
    "\n",
    "Для пользователей pip:\n",
    "\n",
    "!pip install imbalanced-learn\n",
    "\n",
    "Для пользователей anaconda:\n",
    "\n",
    "!conda install -c conda-forge imbalanced-learn\n",
    "\n",
    "Все алгоритмы пересэмплирования находятся в модуле over_sampling библиотеки imblearn. Импортируем оттуда алгоритм SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Примечание. Если вы используете среду Anaconda, у вас может возникнуть следующая ошибка при импорте библиотеки imblearn:\n",
    "\n",
    "###### ImportError: cannot import name '_euclidean_distances' from 'sklearn.metrics.pairwise'\n",
    "\n",
    "###### В этом случае обновите пакеты Anaconda:\n",
    "\n",
    "###### conda update conda\n",
    "\n",
    "###### После этого произведите установку пакета ещё раз:\n",
    "\n",
    "###### !conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим объект класса SMOTE и вызовем у него метод fit_sample(), передав в него обучающую выборку (X_train, y_train). Затем выведем количество наблюдений каждого из классов до и после сэмплирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape before oversampling: (2620, 9)\n",
      "Class balance before oversampling: \n",
      "0    1598\n",
      "1    1022\n",
      "Name: Potability, dtype: int64\n",
      "----------------------------------------\n",
      "Train shape after oversampling: (3196, 9)\n",
      "Class balance after oversampling: \n",
      "0    1598\n",
      "1    1598\n",
      "Name: Potability, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_train_s, y_train_s = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Train shape before oversampling:', X_train.shape) \n",
    "print('Class balance before oversampling: \\n', y_train.value_counts(), sep='')\n",
    "print('-'*40)\n",
    "print('Train shape after oversampling:', X_train_s.shape)\n",
    "print('Class balance after oversampling: \\n', y_train_s.value_counts(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, размер выборки увеличился с 2 620 примеров до 3 196, и теперь количество наблюдений каждого из классов одинаково (1 598/1 598).\n",
    "\n",
    "Попробуем обучить нашу модель на сгенерированных обучающих данных и сделать предсказание на валидационной выборке (обратите внимание, что с валидационным набором данных мы не производим никаких преобразований), чтобы рассчитать метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       400\n",
      "           1       0.63      0.78      0.69       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.73      0.74      0.73       656\n",
      "weighted avg       0.75      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке (с сэмплированием)\n",
    "model.fit(X_train_s, y_train_s)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик    \n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось поднять метрики для класса 1 на валидационной выборке и снова найти баланс между метриками классов. Однако мы потеряли в метриках для класса 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e35777b699d7a7b40cec7735ff85abf8ad01a2c5ba9ffe1b0b11d4c2052d3903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
