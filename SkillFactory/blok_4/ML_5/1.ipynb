{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    " \n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "plt.style.use('seaborn') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_data = pd.read_csv('water_potability.csv')\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Невооруженным глазом видно, что большинство столбцов таблицы являются числовыми. Целевой признак — Potability (пригодность для питья): \n",
    "\n",
    "1 — вода пригодна, \n",
    "\n",
    "0 — вода не пригодна.\n",
    "\n",
    "В данных есть пропуски. Выведем информацию о них в процентном соотношении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 14.987790\n",
       "Hardness            0.000000\n",
       "Solids              0.000000\n",
       "Chloramines         0.000000\n",
       "Sulfate            23.840049\n",
       "Conductivity        0.000000\n",
       "Organic_carbon      0.000000\n",
       "Trihalomethanes     4.945055\n",
       "Turbidity           0.000000\n",
       "Potability          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас отсутствует около 15 % информации о кислотности воды (ph), около 24 % — о содержании сульфатов (Sulfate) и около 5 % — о тригалометанах (Trihalomethanes). Мы знаем, что пропуски — непосильная ноша для большинства моделей машинного обучения. Их необходимо обработать.\n",
    "\n",
    "Заполним пропуски медианным значением в признаке зависимости класса воды (Potability). Для этого сгруппируем данные по признаку Potability, посчитаем медиану в каждой группе, а затем отправим результат в метод fillna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполняем пропуски\n",
    "water_data['ph'] = water_data['ph'].fillna(water_data.groupby('Potability')['ph'].transform('median'))\n",
    "water_data['Sulfate'] = water_data['Sulfate'].fillna(water_data.groupby('Potability')['Sulfate'].transform('median'))\n",
    "water_data['Trihalomethanes'] = water_data['Trihalomethanes'].fillna(water_data.groupby('Potability')['Trihalomethanes'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0.0\n",
       "Hardness           0.0\n",
       "Solids             0.0\n",
       "Chloramines        0.0\n",
       "Sulfate            0.0\n",
       "Conductivity       0.0\n",
       "Organic_carbon     0.0\n",
       "Trihalomethanes    0.0\n",
       "Turbidity          0.0\n",
       "Potability         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Убедимся в отсутствии пропусков:\n",
    "\n",
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь проблема пропусков устранена. \n",
    "# Давайте по традиции разделим набор данных \n",
    "# на матрицу наблюдений X и вектор правильных ответов y:\n",
    "\n",
    "X = water_data.drop('Potability', axis=1)\n",
    "y = water_data['Potability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "основные методы валидации данных ↓\n",
    "\n",
    "### HOLD-OUT\n",
    "\n",
    "Обычно разбиение производится в соотношении 70/30 или 80/20 при двухкомпонентном подходе, и в соотношении 70/15/15 или 80/10/10 — при трёхкомпонентном.\n",
    "\n",
    "РЕАЛИЗАЦИЯ МЕТОДА В SKLEARN\n",
    "\n",
    "Все методы разбиения выборки и валидации, которые мы будем изучать, находятся в модуле model_selection, мы импортировали его заранее.\n",
    "\n",
    "Метод hold-out реализован в уже знакомой вам функции train_test_split(). Она предназначена для разбиения исходного набора данных случайным образом на две части в заданных соотношениях\n",
    "\n",
    "Основные параметры *train_test_split()*:\n",
    "\n",
    "- *arrays — порядковый аргумент с переменным количеством. Набор массивов (это могут быть списки, numpy-массивы, DataFrame), которые подлежат разбиению.\n",
    "- test_size — размер тестовой (валидационной) выборки. Может быть указан в долях. Определяется автоматически, если параметр test_size передан как 1-train_size.\n",
    "- train_size — размер тренировочной выборки. Может быть указан в долях. Определяется автоматически, если параметр test_size передан как 1-test_size.\n",
    "- random_state — число, на основе которого производится генерация случайных чисел.\n",
    "- shuffle — параметр, указывающий, стоит ли перемешивать выборку перед разбиением (по умолчанию True).\n",
    "- stratify — стратифицированное разбиение (о нём мы поговорим в юните по дисбалансу выборки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера разделим выборку в соотношении 80/20 (test_size=0.2), в качестве значения параметра random_state по традиции возьмём число 42.\n",
    "\n",
    "Функция вернёт четыре массива:\n",
    "\n",
    "- таблицу X с обучающими примерами,\n",
    "- таблицу X с примерами для валидации,\n",
    "- столбец y с ответами на обучающие примеры,\n",
    "- столбец y с ответами на валидационные примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (656, 9)\n"
     ]
    }
   ],
   "source": [
    "# Проверим размеры полученных выборок:\n",
    "\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, 2 620 образцов воды являются обучающими — в них модель будет искать закономерности и подбирать внутренние параметры, а 656 являются валидационными — на них мы будем производить контроль качества.\n",
    "\n",
    "Далее нам останется только обучить модель на тренировочной выборке (X_train, y_train) и рассчитать метрики на валидационной выборке (X_valid, y_valid).\n",
    "\n",
    "В качестве модели будем использовать дерево решений с максимальной глубиной 7, энтропией в качестве критерия информативности, минимальное число объектов в листе дерева — 5.\n",
    "\n",
    "После обучения сделаем предсказание для каждой из выборок и рассчитаем метрику. В качестве метрики для простоты возьмём долю правильных ответов — *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hold-out accuracy: 0.82\n",
      "Valid hold-out accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print('Train hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_train, y_train_pred)))\n",
    "print('Valid hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_valid, y_valid_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же мы используем трёхкомпонентный подход (разбиваем выборку на тренировочную, валидационную и отдельную тестовую), тут нам понадобится чуть больше кода. К сожалению, в sklearn нет специализированного функционала для такого разбиения.\n",
    "\n",
    "Применим функцию train_test_split() дважды: сначала разобьём исходный набор на тренировочный и валидационный в соотношении 80/20, затем разобьём валидационный набор на валидационный и тестовый в соотношении 50/50. В итоге наша выборка будет разбита в соотношении 80/10/10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем исходную выборку на тренировочную и валидационную в соотношении 80/20\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = model_selection.train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (328, 9)\n",
      "Test shape: (328, 9)\n"
     ]
    }
   ],
   "source": [
    "# Выводим размерности:\n",
    "\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-FOLD\n",
    "\n",
    "Метод k-fold более известен как кросс-валидация (cross validation), или перекрёстный контроль.\n",
    "\n",
    "Пожалуй, это самый популярный метод валидации для оценки качества моделирования, и он используется практически во всех проектах. Эта идея также применяется во многих моделях и методах машинного обучения, например в стекинге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aлгоритм кросс-валидации:\n",
    "\n",
    "- Разбить исходную выборку на  частей — фолдов (fold).\n",
    "- Повторять  раз:\n",
    "    - Обучить модель на  частях. Назовём их тренировочными фолдами (training fold). \n",
    "    - Произвести оценку качества (вычислить метрику) на оставшейся части. Назовем её валидационным фолдом (validation fold).\n",
    "- Усреднить значения метрики на валидационных фолдах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке sklearn метод k-fold реализован в классе KFold.\n",
    "\n",
    "Основные параметры инициализатора KFold:\n",
    "\n",
    "- n_split —  число фолдов (число $k$ из метода k-fold). По умолчанию — 5.\n",
    "- shuffle — параметр, указывающий, стоит ли перемешивать исходный набор данных перед разбиением. По умолчанию — False.\n",
    "- random_state — число, на основе которого производится генерация случайных чисел, если набор данных будет перемешиваться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта класса KFold есть метод split(). В данный метод необходимо передать матрицу наблюдений X и вектор-столбец ответов y — метод вернёт генератор, который позволит получать индексы тренировочной и валидационной выборок, сгенерированных по методу k-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать двухкомпонентный контроль, то есть подавать в кросс-валидацию весь доступный набор данных без предварительного выделения тестовой выборки.\n",
    "\n",
    "Создадим объект KFold для кросс-валидации с пятью фолдами, остальные параметры оставим по умолчанию. Затем организуем цикл for для получения элементов из генератора, созданного с помощью метода split(). На каждой итерации в переменных train_index и valid_index будут находиться индексы текущей тренировочной и валидационной выборок соответственно.\n",
    "\n",
    "В цикле будем:\n",
    "\n",
    "- выделять строки таблицы, относящиеся к текущим тренировочной и валидационной выборкам, в отдельные таблицы;\n",
    "- обучать дерево решений;\n",
    "- делать предсказания для текущих тренировочной и валидационной выборок;\n",
    "- рассчитывать метрику accuracy на текущих выборках и заносить её значение в список.\n",
    "\n",
    "Код будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "#Создаём список для хранения тренировочных и валидационных метрик\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "#Организуем цикл для кросс-валидации (используем весь набор данных)\n",
    "#train_index — индексы тренировочной выборки\n",
    "#valid_index — индексы валидационной выборки\n",
    "for train_index, valid_index in kf.split(X, y): \n",
    "    #Создаём тренировочную и валидационную выборку, обращаясь по текущим индексам\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    #Обучаем случайный лес на тренировочной выборке\n",
    "    model.fit(X_train, y_train)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    #Рассчитываем метрику и заносим её в список\n",
    "    train_metrics.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    val_metrics.append(metrics.accuracy_score(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
      "[0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]\n"
     ]
    }
   ],
   "source": [
    "#Выведем содержимое массивов train_metrics и val_metrics:\n",
    "\n",
    "print(train_metrics)\n",
    "print(val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждом из выведенных списков содержится по пять значений метрики accuracy, вычисленных на тренировочном и валидационном фолдах кросс-валидации. Для агрегированной оценки рассчитаем среднее значение метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(train_metrics)))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(val_metrics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласитесь, сложновато — не совсем в стиле sklearn. Тут и циклы, и генераторы... Неужели каждый раз придётся писать подобный код для проведения кросс-валидации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно же, нет. На самом весь приведённый выше код можно значительно сократить, если использовать специальную функцию для кросс-валидации — *cross_validate()* из модуля *model_selection*. Она организует процедуру кросс-валидации и расчёт метрик.\n",
    "\n",
    "Основные параметры функции *cross_validate()*:\n",
    "\n",
    "- estimator — модель, качество которой будет проверяться на кросс-валидации.\n",
    "- X — матрица наблюдений.\n",
    "- y — вектор-столбец правильных ответов.\n",
    "- cv — кросс-валидатор из библиотеки sklearn (например, KFold) или количество фолдов, на которые необходимо разбить выборку. По умолчанию используется кросс-валидация на пяти фолдах.\n",
    "- scoring — название метрики в виде строки либо функция для её вычисления *('accuracy', 'precision', 'recall', 'f1'* и другие; полный список — в документации к функции).\n",
    "- return_train_score — параметр, указывающий стоит ли возвращать значения метрики, полученных на тренировочных фолдах. По умолчанию — False, то есть метрики считаются только на валидационных фолдах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция возвращает словарь со следующими ключами:\n",
    "\n",
    "- fit_time — время обучения модели на каждой итерации кросс-валидации;\n",
    "- score_time — время вычисления метрик на каждой итерации кросс-валидации;\n",
    "- test_score — значения метрик на валидационных фолдах;\n",
    "- train_score — значения метрик на тренировочных фолдах.\n",
    "\n",
    "Итоговый код с использованием функции cross_validate() будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04197311, 0.03997374, 0.03797483, 0.02998114, 0.02998018]),\n",
       " 'score_time': array([0.00406861, 0.00299931, 0.00100064, 0.00199866, 0.00199962]),\n",
       " 'test_score': array([0.79573171, 0.70534351, 0.73587786, 0.72824427, 0.73282443]),\n",
       " 'train_score': array([0.80343511, 0.81686379, 0.80274704, 0.82678367, 0.81571919])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=kf, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В массивах, хранящихся по ключам train_score и test_score, содержится по пять значений метрики accuracy, полученных на тренировочных и валидационных фолдах соответственно на каждой итерации кросс-валидации. Давайте рассчитаем среднее и сравним его с результатом, полученным ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили тот же результат, что и ранее. Согласитесь, функция cross_validate() значительно облегчает работу с кросс-валидацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAVE-ONE-OUT\n",
    "\n",
    "Метод leave-one-out (отложенный пример), или поэлементная кросс-валидация — это частный случай кросс-валидации (k-fold), когда размер $k$ равняется размеру всей выборки $k=n$, где $n$ — количество примеров (строк в таблице)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм метода:\n",
    "\n",
    "1. Повторять  раз:\n",
    "    - Выбрать один случайный пример для валидации.\n",
    "    - Обучить модель на всех оставшихся $n-1$ примерах.\n",
    "    - Произвести оценку качества (вычислить метрику) на отложенном примере.\n",
    "2. Усреднить значение метрик на всех примерах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РЕАЛИЗАЦИЯ МЕТОДА В SKLEARN\n",
    "\n",
    "В библиотеке sklearn метод leave-one-out реализован в классе LeaveOneOut. Параметров инициализации у данного класса нет.\n",
    "\n",
    "Работа с кросс-валидатором полностью идентична работе с KFold, который мы рассматривали ранее (цикл для организации кросс-валидации вручную будет выглядеть аналогично).\n",
    "\n",
    "Объект класса LeaveOneOut также можно передать в функцию cross_validate() для получения метрик на каждом из примеров. В случае с метрикой accuracy список будет состоять из 0 и 1 (0 — модель не угадала класс на отложенном примере, 1 — модель угадала класс на отложенном примере).\n",
    "\n",
    "Так как датасет у нас довольно большой (более трёх тысяч образцов воды), алгоритм кросс-валидации leave-one-out будет выполняться очень долго. Для экономии времени выполнения кода будем использовать первые 500 наблюдений из исходной таблицы.\n",
    "\n",
    "Примечание. Значение метрики будет рассчитано не для всего набора данных, а только для его части. Если вы захотите рассчитать метрику на всём наборе данных, вместо среза передавайте в функцию таблицу X и столбец y целиком. Но имейте в виду, что код в таком случае может выполняться до нескольких минут.\n",
    "\n",
    "Итоговый код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.95\n",
      "Valid k-fold mean accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём кросс-валидатор LeaveOneOut\n",
    "loo = model_selection.LeaveOneOut()\n",
    " \n",
    "#Считаем метрики на кросс-валидации leave-one-out\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X.iloc[:500], #матрица наблюдений X\n",
    "    y=y.iloc[:500], #вектор ответов y\n",
    "    cv=loo, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Метод leave-one-out можно реализовать и без использования специального класса — достаточно просто указать параметр n_split=n в инициализаторе KFold, где n — количество строк в таблице."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дисбаланс выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.60989\n",
       "1    0.39011\n",
       "Name: Potability, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Рассмотрим влияние дисбаланса на примере датасета о качестве воды.\n",
    "# Посмотрим на соотношения классов внутри датасета:\n",
    "\n",
    "display(water_data['Potability'].value_counts(normalize=True))\n",
    "sns.countplot(data=water_data, x='Potability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, около 61 % образцов воды являются непригодными для питья и 39 % являются пригодными. На самом деле это небольшой дисбаланс классов (61/39). В реальных задачах мы можете столкнуться и с куда более неравномерными соотношениями, например 80/20, 90/10 или даже 99/1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим особенности разбиения выборок в условиях дисбаланса классов.\n",
    "\n",
    "### СТРАТИФИЦИРОВАННОЕ РАЗБИЕНИЕ\n",
    "\n",
    "Для того чтобы снизить влияние дисбаланса классов при разбиении выборки, в наборе данных используется специальный тип разбиения, который называется стратифицированным (stratified). Данное разбиение предполагает, что наблюдения, принадлежащие каждому из классов, гарантированно попадут в каждый из наборов данных в одинаковой пропорции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте на на примере рассмотрим, как производить стратифицированное разбиение. Начнём с простого разделения hold-out, которое мы проводим с помощью функции train_test_split(). Для начала проведём обычное случайное разбиение на тренировочную и валидационную выборку (в соотношении 80/20) без стратификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.620229\n",
      "1    0.379771\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.568598\n",
      "1    0.431402\n",
      "Name: Potability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X, y = water_data.drop('Potability', axis=1), water_data['Potability']\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что соотношения классов в тренировочной выборке — 62/38, а в тестовой — 57/43. Давайте попробуем сбалансировать соотношения.\n",
    "\n",
    "Для стратифицированного разбиения достаточно в функции train_test_split() задать параметр stratify, в который нужно передать столбец с метками классов, на основе которого будет производиться балансировка. Это будет столбец с правильными ответами y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.609924\n",
      "1    0.390076\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.609756\n",
      "1    0.390244\n",
      "Name: Potability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)\n",
    "print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь в каждом из наборов данных одинаковые соотношения классов — 61/39. Метрики, полученные при одинаковых соотношениях на выборках, будут более объективными.\n",
    "\n",
    "**А что насчёт кросс-валидации? Как организовать разбиение по методу k-fold и получить одинаковые соотношения классов?**\n",
    "\n",
    "Для этого вместо KFold используется кросс-валидатор StratifiedKFold. Принцип работы с ним аналогичен, только, в отличие от KFold, StratifiedKFold будет разбивать выборку на части таким образом, чтобы в тренировочных и валидационных фолдах соотношения классов были приблизительно одинаковыми.\n",
    "\n",
    "Давайте напишем код, который организует стратифицированное k-fold-разбиение на три фолда, и выведем соотношения классов в каждой из выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n",
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n",
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "skf = model_selection.StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "for train_index, valid_index in skf.split(X, y): \n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "    print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что соотношения классов в тренировочной и валидационной выборках в каждом разбиении примерно одинаковы — 61/39.\n",
    "\n",
    "Так же, как и другие кросс-валидаторы, объект класса StratifiedKFold может быть использован в функции cross_validate()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.3\n",
    "\n",
    "\n",
    "Ниже представлен код для генерации задачи классификации и отрисовки диаграммы рассеяния с цветовой группировкой по классам:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте исходный набор данных на тренировочный и валидационный со стратификацией по классам в соотношении 80/20. В качестве значения параметра random_state возьмите число 42.\n",
    "\n",
    "Постройте диаграммы рассеяния с цветовой группировкой по классам для валидационной выборки.\n",
    "\n",
    "Из приведённых ниже диаграмм выберите ту, которая соответствует полученному разбиению:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВЫБОР МЕТРИК В УСЛОВИЯХ ДИСБАЛАНСА КЛАССОВ\n",
    "\n",
    "Давайте на примере посмотрим, насколько важен выбор метрики в случае дисбаланса выборки.\n",
    "\n",
    "Разобьём выборку на тренировочную и валидационную в соотношении 80/20, используя стратифицированное разбиение, затем обучим модель дерева решений, сделаем предсказание для каждой из выборок и сформируем отчёт о метриках на валидационной выборке с помощью функции classification_report()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       400\n",
      "           1       0.81      0.55      0.65       256\n",
      "\n",
      "    accuracy                           0.77       656\n",
      "   macro avg       0.78      0.73      0.74       656\n",
      "weighted avg       0.78      0.77      0.76       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print(metrics.classification_report(y_valid, y_valid_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из отчёта о метриках классификации видно, что для валидационной выборки метрика accuracy составляет 0.77, что, в принципе, является довольно хорошим результатом. Однако если мы посмотрим на метрики recall и f1-score для каждого из классов в отдельности, мы увидим, что метрики для класса 0 значительно выше, чем метрики для класса 1.\n",
    "\n",
    "- Precision для класса 1 составляет 0.81, то есть из всех образцов воды, причисленных моделью к классу пригодных для питья, 81 % действительно являются таковыми.\n",
    "- Recall для класса 1 составляет 0.55, то есть из всех образцов в действительности пригодной для питья воды модель посчитала пригодными лишь 55 %, а остальные 45 % посчитала непригодными.\n",
    "- $F1$-мера — среднее гармоническое между precision и recall — составила 0.65 для класса 1 и 0.83 — для класса 0. Разница довольно далека от нуля, а значит построенная нами модель больше контролируется на образцах воды, непригодных для питья, и обладает плохой различающей способностью.\n",
    "Однако мы не смогли бы выявить этот факт, если бы ориентировались только на метрику accuracy. Одной из причин такого результата является дисбаланс классов: образцов непригодной для питья попросту больше, чем пригодных для питья.\n",
    "\n",
    "Примечание. Поскольку простая accuracy вызывает сомнения в задачах с сильным дисбалансом, были разработаны специальные метрики, основанные на accuracy: это функционал Каппа Коэна (Cohen’s Kappa) и balanced accuracy. Подробнее о них вы можете прочитать здесь (https://dyakonov.org/2019/05/31/функционалы-качества-в-задаче-бинарн/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.5\n",
    "\n",
    "Для выполнения этого задания используйте сгенерированные тренировочную и валидационную выборки из задания 3.3.\n",
    "\n",
    "Обучите модель логистической регрессии на тренировочной выборке (все параметры оставьте по умолчанию).\n",
    "\n",
    "Сделайте предсказание для валидационной выборки и рассчитайте метрики классификации. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПОСТРОЕНИЕ МОДЕЛИ В УСЛОВИЯХ ДИСБАЛАНСА КЛАССОВ\n",
    "\n",
    "Итак, мы посмотрели, как дисбаланс выборки может оказывать влияние на способность модели находить класс меньшинства. Но как с этим бороться?\n",
    "\n",
    "Существует **несколько способов уменьшить влияние дисбаланса на обучение модели:**\n",
    "\n",
    "- **Взвешивание объектов.** В функцию ошибки добавляется штраф, прямо пропорциональный количеству объектов каждого класса. Это очень похоже на регуляризацию, которую мы изучали ранее.\n",
    "- **Выбор порога вероятности.** Этот подход мы с вами тоже уже использовали ранее. Он заключается в том, что мы подбираем такой порог вероятности (по умолчанию он равен 0.5 во всех моделях), при котором на валидационной выборке максимизируется целевая метрика (например, $F1$-score).\n",
    "- **Сэмплирование (sampling)** — перебалансировка выборки искусственным путём:\n",
    "oversampling — искусственное увеличение количества объектов миноритарного класса;\n",
    "undersampling — сокращение количества объектов мажоритарного класса.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь могут использоваться алгоритмы генерации искусственных данных, такие как NearMiss, SMOTE (Synthetic Minority Oversampling Techniques) и ADASYN (Adaptive Synthetic).\n",
    "\n",
    "Мы рассмотрим наиболее популярный алгоритм — SMOTE, об остальных можно прочитать здесь (https://dyakonov.org/2021/05/27/imbalance/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ВЗВЕШИВАНИЕ ОБЪЕКТОВ\n",
    "\n",
    "Для того чтобы задать веса классам, достаточно в инициализаторе модели выставить параметр class_weight='balanced'.\n",
    "\n",
    "Посмотрим на реализацию на примере дерева решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       400\n",
      "           1       0.63      0.76      0.69       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.72      0.73      0.72       656\n",
      "weighted avg       0.74      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик    \n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.7\n",
    "\n",
    "Для выполнения этого задания используйте сгенерированные тренировочную и валидационную выборки из задания 3.3.\n",
    "\n",
    "Обучите модель логистической регрессии на тренировочной выборке, уставив сбалансированные веса для классов.\n",
    "\n",
    "Сделайте предсказание для валидационной выборки и рассчитайте метрики классификации. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3.8 (на самопроверку)\n",
    "\n",
    "Воспользуйтесь функцией plot_probabilities_2d(), которую мы написали в модуле по классификации, для того, чтобы построить разделяющую поверхность логистической регрессии со сбалансированными весами классов.\n",
    "\n",
    "Примечание. Код функции plot_probabilities_2d() вы можете найти в задании 3.6.\n",
    "\n",
    "Передайте в её аргументы матрицу наблюдений X, вектор ответов y и обученную в задании 3.7 логистическую регрессию.\n",
    "\n",
    "Сравните разделяющую поверхность, построенную в задании 3.5, с полученной вами поверхностью в данном задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ВЫБОР ПОРОГА ВЕРОЯТНОСТИ. PR-КРИВАЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед построением PR-кривой нам необходимо предсказать вероятности принадлежности к классу 1 на валидационных фолдах кросс-валидации.\n",
    "\n",
    "Для предсказания вероятностей используем функцию cross_val_predict(). Данная функция выполняет кросс-валидацию и возвращает предсказания для валидационных фолдов. Если ей передать параметр method='predict_proba', она вернёт предсказанные вероятности для каждого из классов на всех фолдах. Остальные параметры аналогичны параметрам функции cross_validate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел \n",
    ")\n",
    "#Обучаем модель\n",
    "model.fit(X_train, y_train)\n",
    "#Создаём кросс-валидатор k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "#Делаем предсказание вероятностей на кросс-валидации\n",
    "y_cv_proba_pred = model_selection.cross_val_predict(model, X_train, y_train, cv=skf, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.24561404, 0.75438596],\n",
       "       [1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.60621762, 0.39378238],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03030303, 0.96969697]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv_proba_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это массив из вероятностей для каждого образца воды. Первое число в строке — вероятность того, что данный образец является непригодным для питья, а второе — вероятность того, что данный образец пригоден для питья.\n",
    "\n",
    "Нас интересует класс 1 (пригодная для питья вода). Это второй столбец в матрице вероятностей (индекс 1). Выделим этот столбец из матрицы с вероятностями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделяем столбец с вероятностями для класса 1 \n",
    "y_cv_proba_pred = y_cv_proba_pred[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем построить PR-кривую. Для этого воспользуемся функций precision_recall_curve() из модуля metrics библиотеки sklearn. В данную функцию нужно передать истинные метки классов и предсказанные вероятности. Взамен она вернёт три массива: значения метрик precision и recall, вычисленных на различных порогах вероятности, и сами пороги вероятности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds: [0.         0.02739726 0.02898551 0.05       0.07407407]\n",
      "Precision scores: [0.39007634 0.50050659 0.50357873 0.50437919 0.5043837 ]\n",
      "Recall scores: [1.         0.9667319  0.96379648 0.95792564 0.95694716]\n"
     ]
    }
   ],
   "source": [
    "#Вычисляем координаты PR-кривой\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_train, y_cv_proba_pred)\n",
    "\n",
    "print('Thresholds:', thresholds[:5])\n",
    "print('Precision scores:', precision[:5])\n",
    "print('Recall scores:',recall[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось дело за малым. Вычислим значение $F1$-score при различных порогах вероятности и найдём такой порог вероятности, при котором она максимальна. Сделать это можно с помощью функции argmax() из модуля numpy — она возвращает индекс максимального элемента массива.\n",
    "\n",
    "Далее построим PR-кривую и отметим на ней точку максимума $F1$-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold = 0.33, F1-Score = 0.69\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Вычисляем F1-score при различных threshold\n",
    "f1_scores = (2 * precision * recall) / (precision + recall)\n",
    "#Определяем индекс максимума\n",
    "idx = np.argmax(f1_scores)\n",
    "print('Best threshold = {:.2f}, F1-Score = {:.2f}'.format(thresholds[idx], f1_scores[idx]))\n",
    " \n",
    "#Строим PR-кривую\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) #фигура + координатная плоскость\n",
    "#Строим линейный график зависимости precision от recall\n",
    "ax.plot(precision, recall, label='Decision Tree PR')\n",
    "#Отмечаем точку максимума F1\n",
    "ax.scatter(precision[idx], recall[idx], marker='o', color='black', label='Best F1 score')\n",
    "#Даём графику название и подписываем оси\n",
    "ax.set_title('Precision-recall curve')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "#Отображаем легенду\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, согласно нашим вычислениям и построенной PR-кривой, максимум  (0.69) на кросс-валидации наблюдается при пороге вероятности 0.33.\n",
    "\n",
    "Сделаем предсказание классов с таким порогом для всех объектов из отложенной валидационной выборки и выведем отчёт о метриках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76       400\n",
      "           1       0.62      0.76      0.68       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.72      0.73      0.72       656\n",
      "weighted avg       0.74      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Образцы воды, для которых вероятность быть пригодными для питья > threshold_opt, относим к классу 1\n",
    "#В противном случае — к классу 0\n",
    "y_valid_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "y_valid_pred = (y_valid_pred_proba > 0.33).astype('int') # Best threshold = 0.33 (threshold_opt)\n",
    "#Считаем метрики\n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, при применении метода подбора вероятности увеличилось значение метрик recall и  для класса 1. Нам удалось сократить разницу метрик между классами и заставить модель практически одинаково хорошо предсказывать классы питьевой и непитьевой воды.\n",
    "\n",
    "Примечание. Чтобы вычислить площадь под PR-кривой, используется функция auc() из модуля metrics библиотеки sklearn. В данную функцию нужно передать значения метрик recall и precision при различных порогах вероятности:\n",
    "\n",
    "print('PR AUC: {:.2f}'.format(metrics.auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('PR AUC: {:.2f}'.format(metrics.auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СЭМПЛИРОВАНИЕ\n",
    "\n",
    "Следующий подход работы в условиях дисбаланса классов, который мы рассмотрим, — сэмплирование, а точнее — пересэмплирование (oversampling).\n",
    "\n",
    "Идея очень проста: если у нас мало наблюдений миноритарного класса, следует искусственно увеличить их количество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "алгоритм SMOTE (Synthetic Minority Oversampling Techniques).\n",
    "\n",
    "В основе алгоритма лежит идея генерации некоторого количества искусственных наблюдений, которые были бы «похожи» на наблюдения, имеющиеся в миноритарном классе, но при этом не дублировали их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмов сэмплирования, в том числе SMOTE, нет в стандартном пакете sklearn — \n",
    "они содержатся в библиотеке imblearn (imbalanced-learn). \n",
    "Команды для установки приведены далее.\n",
    "\n",
    "Для пользователей pip:\n",
    "\n",
    "!pip install imbalanced-learn\n",
    "\n",
    "Для пользователей anaconda:\n",
    "\n",
    "!conda install -c conda-forge imbalanced-learn\n",
    "\n",
    "Все алгоритмы пересэмплирования находятся в модуле over_sampling библиотеки imblearn. Импортируем оттуда алгоритм SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Примечание. Если вы используете среду Anaconda, у вас может возникнуть следующая ошибка при импорте библиотеки imblearn:\n",
    "\n",
    "###### ImportError: cannot import name '_euclidean_distances' from 'sklearn.metrics.pairwise'\n",
    "\n",
    "###### В этом случае обновите пакеты Anaconda:\n",
    "\n",
    "###### conda update conda\n",
    "\n",
    "###### После этого произведите установку пакета ещё раз:\n",
    "\n",
    "###### !conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим объект класса SMOTE и вызовем у него метод fit_sample(), передав в него обучающую выборку (X_train, y_train). Затем выведем количество наблюдений каждого из классов до и после сэмплирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape before oversampling: (2620, 9)\n",
      "Class balance before oversampling: \n",
      "0    1598\n",
      "1    1022\n",
      "Name: Potability, dtype: int64\n",
      "----------------------------------------\n",
      "Train shape after oversampling: (3196, 9)\n",
      "Class balance after oversampling: \n",
      "0    1598\n",
      "1    1598\n",
      "Name: Potability, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_train_s, y_train_s = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Train shape before oversampling:', X_train.shape) \n",
    "print('Class balance before oversampling: \\n', y_train.value_counts(), sep='')\n",
    "print('-'*40)\n",
    "print('Train shape after oversampling:', X_train_s.shape)\n",
    "print('Class balance after oversampling: \\n', y_train_s.value_counts(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, размер выборки увеличился с 2 620 примеров до 3 196, и теперь количество наблюдений каждого из классов одинаково (1 598/1 598).\n",
    "\n",
    "Попробуем обучить нашу модель на сгенерированных обучающих данных и сделать предсказание на валидационной выборке (обратите внимание, что с валидационным набором данных мы не производим никаких преобразований), чтобы рассчитать метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       400\n",
      "           1       0.63      0.78      0.69       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.73      0.74      0.73       656\n",
      "weighted avg       0.75      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке (с сэмплированием)\n",
    "model.fit(X_train_s, y_train_s)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик    \n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось поднять метрики для класса 1 на валидационной выборке и снова найти баланс между метриками классов. Однако мы потеряли в метриках для класса 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Недообучение и переобучение. Утечка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KАК ОБНАРУЖИТЬ ПЕРЕОБУЧЕНИЕ\n",
    "\n",
    "Переобучение легко детектируется с помощью изученных нами методов валидации: мы намеренно разбиваем выборку на тренировочную и валидационную (возможно, и тестовую) и смотрим на значения показателей на каждой из выборок, сравнивая их между собой.\n",
    "\n",
    "Основные способы отследить переобучение:\n",
    "\n",
    "- hold-out-разбиение,\n",
    "- k-fold-валидация и leave-one-out-валидация,\n",
    "- кривые обучения (learning curves).\n",
    "\n",
    "Если качество на валидационной выборке стабильно хуже качества на тренировочной, то это явный признак переобучения.\n",
    "\n",
    "Рассмотрим пример. Будем использовать тот же набор данных об образцах воды.\n",
    "\n",
    "Сначала проверим модель на переобучение с помощью отложенной (hold-out) выборки.\n",
    "\n",
    "Для этого стратифицированно разобьём набор данных на тренировочную и валидационную выборки в соотношении 80/20 и обучим дерево решений с энтропией  в качестве критерия информативности и сбалансированными весами классов без ограничения его глубины и количества объектов в листе. Сделаем предсказание для каждой из выборок и рассчитаем метрику $F1$-score:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 score: 1.00\n",
      "Valid F1 score: 0.67\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "#Создаём модель\n",
    "model_bad = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    class_weight='balanced', #веса классов\n",
    "    random_state=42 #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model_bad.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model_bad.predict(X_train)\n",
    "y_valid_pred = model_bad.predict(X_valid)\n",
    "#Выводим значения метрик для тренировочной выборки\n",
    "print('Train F1 score: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "#Выводим значения метрик для валидационной выборки\n",
    "print('Valid F1 score: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    " \n",
    "# Train F1 score: 1.00\n",
    "# Valid F1 score: 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Значение $F1$-score на тренировочной выборке показывает, что задача классификации образцов воды на пригодные и непригодные для питья решена идеально. Метрика равна максимуму — 1, а значит, и precision и recall для каждого из классов равны 1 (значит, и значения всех остальных метрик тоже максимальны). То есть модель правильно определила класс для всех образцов воды из набора данных.\n",
    "- Однако значение $F1$-score, полученное на валидационной выборке, менее оптимистично. Значение метрики на контроле значительно ниже, чем при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это типичная картина переобучения: модель дерева решений полностью адаптировалась под обучающий набор данных, но не нашла общих закономерностей, поэтому результаты на контроле оставляют желать лучшего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим гипотезу о наличии переобучения у нашего дерева с помощью кросс-валидации k-fold. Организуем стратифицированную кросс-валидацию на пяти фолдах. На каждом шаге кросс-валидации будем вычислять метрику $F1$ на тренировочных и валидационных фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.05896449, 0.05796313, 0.05196762, 0.04597092, 0.06196332]),\n",
       " 'score_time': array([0.00699615, 0.00299573, 0.00299907, 0.00499821, 0.00399852]),\n",
       " 'test_score': array([0.61445783, 0.68421053, 0.62332696, 0.63276836, 0.70119522]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model_bad, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В полученном словаре невооруженным глазом видно, что на тренировочных фолдах значения метрик равны 1, а вот на валидационных метрика ни разу не превысила значения 0.7.\n",
    "\n",
    "Подсчитаем среднее значение $F1$-score на выборках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 1.00\n",
      "Valid k-fold mean f1: 0.65\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "## Train k-fold mean f1: 1.00\n",
    "## Valid k-fold mean f1: 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МЕТОДЫ БОРЬБЫ С ПЕРЕОБУЧЕНИЕМ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. УМЕНЬШЕНИЕ СЛОЖНОСТИ МОДЕЛИ\n",
    "    Это основной способ борьбы с переобучением, так как, по сути, повышенная сложность модели и является его причиной.\n",
    "\n",
    "    Рекомендации по уменьшению сложности моделей\n",
    "    - **Для линейной (логистической) регрессии** с полиномиальными признаками уменьшение сложности модели означает понижение степени полинома.\n",
    "    \n",
    "    Ниже приведены три полиномиальных модели, которые решают одну и ту же задачу, — полином первой (простая линейная регрессия), четвёртой и пятнадцатой степени. Для каждой модели рассчитана MSE (средний квадрат ошибки) между предсказанными значениями и истинной функцией. Видно, что наименьшей ошибкой обладает полином четвёртой степени.\n",
    "    - **Для деревьев решений** — «стрижка» (pruning) деревьев, то есть уменьшение их глубины (max_depth) и/или увеличение количества объектов, при которых вершина дерева превращается в лист (min_samples_leaf).\n",
    "    - **Для случайного леса** — «стрижка» деревьев (max_depth и min_samples_leaf) и уменьшение количества признаков, на которых обучается каждое дерево (max_features).\n",
    "\n",
    "    Пример переобученного дерева решений и его разделяющей поверхности до обрезки:\n",
    "2. РЕГУЛЯРИЗАЦИЯ\n",
    "    С помощью добавления штрафа в функцию потерь мы намеренно пытаемся увеличить смещение модели, чтобы уменьшить разброс. Закон баланса в действии!\n",
    "\n",
    "    Ранее мы изучали регуляризацию только в контексте линейных моделей, но на самом деле она есть и во многих других методах машинного обучения, с которыми мы будем знакомиться в дальнейшем.\n",
    "\n",
    "    На рисунке ниже приведено несколько примеров одной и той же модели — полинома восьмой степени с различными коэффициентами регуляризации (обозначен как $lambda$). Видно, что чем выше $lambda$, тем меньше переобучение. Однако есть риск увеличить $lambda$  слишком сильно, и тогда модель превратится в недообученную (левый нижний рисунок).\n",
    "3. МАНИПУЛЯЦИИ С ДАННЫМИ\n",
    "    Ещё один верный способ побороть переобучение — увеличить или уменьшить количество примеров, на которых обучается модель.\n",
    "\n",
    "    - Увеличивать набор данных можно за счёт проведения новых экспериментов и сбора новой информации.\n",
    "    - Уменьшать набор данных можно за счёт удаления выбросов и аномалий из обучающего набора данных, из-за которых отчасти и происходит переобучение модели.\n",
    "    \n",
    "    Также можно отбирать наиболее значимые признаки, которые в наибольшей степени влияют на предсказания модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала необходимо разобраться в причине переобучения модели. Для дерева решений установленный по умолчанию параметр max_depth будет означать, что дерево будет делиться до тех пор, пока не определит правильный класс для каждого объекта из обучающего набора данных.\n",
    "\n",
    "На реальных данных, подверженных зашумлённости, такой подход в большинстве случаев приводит к переобучению дерева: глубина становится очень большой, и дерево не отражает общих зависимостей в данных.\n",
    "\n",
    "В таком случае в первую очередь прибегают к «обрезке» деревьев путём ограничения максимальной глубины и/или увеличения количества объектов, при которых вершина дерева превращается в лист и деление прекращается.\n",
    "\n",
    "Для начала посмотрим на текущую глубину дерева:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current depth: 27\n"
     ]
    }
   ],
   "source": [
    "print('Current depth:', model_bad.get_depth())\n",
    "## Current depth: 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево глубиной 27 — это очень сложная модель. Давайте попробуем её упростить, добавив в дерево решений ограничение на глубину (max_depth). Пусть максимальная глубина дерева будет равна 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 0.75\n",
      "Valid k-fold mean f1: 0.66\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #ограничиваем глубину дерева\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "\n",
    "\n",
    "## Train k-fold mean f1: 0.75\n",
    "## Valid k-fold mean f1: 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После ограничения максимальной глубины удалось уменьшить разницу между метриками на тренировочных и валидационных фолдах кросс-валидации.\n",
    "\n",
    "Попробуйте самостоятельно изменять глубину дерева в большую и меньшую сторону и проследите, как меняется значение метрик на кросс-валидации.\n",
    "\n",
    "Попробуем добавить ещё одно ограничение к нашему дереву: увеличим количество объектов, которых достаточно для образования листа дерева (min_samples_leaf). По умолчанию этот параметр равен 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним интерпретацию данного параметра. Пусть min_samples_leaf=5. Допустим, в результате разделения получается две вершины: первая — с четырьмя объектами, а вторая — с шестью. Тогда дерево разрешит снова делиться только второй вершине (6 > min_samples_leaf), а первая вершина (4 < min_samples_leaf) дерева превратится в лист, и её деление будет остановлено."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 0.74\n",
      "Valid k-fold mean f1: 0.66\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #ограничиваем глубину дерева\n",
    "    min_samples_leaf=5, #увеличиваем количество объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "## Train k-fold mean f1: 0.74\n",
    "## Valid k-fold mean f1: 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось ещё немного сократить разницу между метриками на тренировочных и валидационных фолдах и уменьшить переобучение.\n",
    "\n",
    "Примечание. В приведённом выше примере мы выбирали параметры исключительно по принципу «холодно-горячо». Конечно же, в реальности никто так не делает — существуют специальные механизмы перебора комбинаций внешних параметров модели, и мы познакомимся с ними в отдельном модуле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### УТЕЧКА ДАННЫХ\n",
    "\n",
    "#### КАК ОБНАРУЖИТЬ УТЕЧКУ ДАННЫХ\n",
    "\n",
    "- **Читайте описание признаков.**\n",
    "\n",
    "Из описания признаков всегда можно узнать полезную информацию и обнаружить утечку с помощью банальной логики. Если вы предсказываете цену товара, а в вашем наборе данных есть признак цены этого товара со скидкой, очевидно, что данный признак стоит удалить из обучающего набора данных.\n",
    "\n",
    "- **Проверяйте корреляции с целевым признаком.**\n",
    "\n",
    "В процессе разведывательного анализа вы можете обнаружить признаки, которые очень сильно коррелируют с целевой переменной. Конечно, такая корреляция может быть естественной и не сопровождаться утечкой, например корреляция между количеством комнат в квартире и её ценой. Однако высокая степень корреляции между налоговой выплатой за продажу и ценой квартиры — это яркий пример утечки.\n",
    "\n",
    "- **Относитесь скептически к подозрительно высокому качеству моделей.**\n",
    "\n",
    "При построении модели вас может насторожить слишком высокое качество даже самых простых моделей, которого в реальных условиях достичь не удалось бы. Это может быть сигналом о наличии утечки данных.\n",
    "\n",
    "Поэтому для начала старайтесь строить baseline — простые модели машинного обучения, такие как логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кривая обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПОСТРОЕНИЕ КРИВОЙ ОБУЧЕНИЯ\n",
    "\n",
    "Давайте научимся строить кривые обучения с помощью Python. \n",
    "\n",
    "Для вычисления точек для построения кривых обучения в модуле model_selection библиотеки sklearn есть функция learning_curve().\n",
    "\n",
    "Основные параметры функции learning_curve():\n",
    "\n",
    "- estimator — модель, качество которой будет проверяться на кросс-валидации.\n",
    "- X — матрица наблюдений.\n",
    "- y — вектор-столбец правильных ответов.\n",
    "- train_sizes — относительное (долевое) или абсолютное количество обучающих примеров, которые будут использоваться для создания кривой обучения. Если dtype имеет значение float, он рассматривается как часть максимального размера обучающего набора (который определяется выбранным методом проверки), т. е. он должен быть в пределах (0, 1].\n",
    "\n",
    "    По умолчанию используется список [0.1, 0.325, 0.55, 0.775, 1.0], то есть для построения кривой обучения используется пять точек. Первая точка кривой обучения строится по 10 % наблюдений из обучающего набора, вторая точка — по 32.5 % и так далее до тех пор, пока в построении модели не будет участвовать весь обучающий набор данных.\n",
    "- cv — кросс-валидатор из библиотеки sklearn (например, KFold) или количество фолдов, на которые необходимо разбить выборку. По умолчанию используется кросс-валидация k-fold на пяти фолдах.\n",
    "- scoring — название метрики в виде строки либо функция для её вычисления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если передать функции все необходимые параметры, она вернёт три массива:\n",
    "\n",
    "- Список из размеров тренировочного набора (ось абсцисс кривой обучения).\n",
    "- Матрица из метрик, полученных при разных размерах тренировочного набора во время кросс-валидации на тренировочных фолдах. В строках этой таблицы указаны списки метрик, соответствующие каждому размеру тренировочного набора данных, а внутри списков находятся сами метрики на кросс-валидации.\n",
    "- Матрица из метрик, полученных при разных размерах тренировочного набора во время кросс-валидации на валидационных фолдах.\n",
    "\n",
    "Код для вычисления координат будет иметь следующий вид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sizes: \n",
      " [ 262  851 1441 2030 2620]\n",
      "Train scores: \n",
      " [[0.8        0.72727273 0.72727273 0.72727273 0.72727273]\n",
      " [0.76156584 0.82522523 0.8757764  0.8757764  0.8757764 ]\n",
      " [0.78546099 0.80108011 0.78497653 0.78183613 0.78183613]\n",
      " [0.75440806 0.74526573 0.72822528 0.76443265 0.75997384]\n",
      " [0.73336393 0.75992939 0.72322275 0.74051593 0.76085963]]\n",
      "Valid scores: \n",
      " [[0.62222222 0.2228739  0.18128655 0.25329815 0.28486647]\n",
      " [0.64528302 0.4978903  0.46031746 0.53831776 0.56928839]\n",
      " [0.59622642 0.60687023 0.60805861 0.56624319 0.60820896]\n",
      " [0.60903733 0.68641115 0.63859649 0.59344894 0.67407407]\n",
      " [0.61981982 0.6797153  0.66294227 0.61689587 0.71719039]]\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    class_weight='balanced', \n",
    "    random_state=42, #генератор случайных чисел \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Вычисляем координаты для построения кривой обучения\n",
    "train_sizes, train_scores, valid_scores = model_selection.learning_curve(\n",
    "    estimator = model, #модель\n",
    "    X = X, #матрица наблюдений X\n",
    "    y = y, #вектор ответов y\n",
    "    cv = skf, #кросс-валидатор\n",
    "    scoring = 'f1' #метрика\n",
    ")\n",
    "print('Train sizes: \\n', train_sizes)\n",
    "print('Train scores: \\n', train_scores)\n",
    "print('Valid scores: \\n', valid_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы вычислить среднюю кросс-валидационную метрику на каждом из наборов данных, необходимо рассчитать среднее по столбцам матриц train_scores и valid_scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold f1 scores [0.74181818 0.84282405 0.78703798 0.75046111 0.74357833]\n",
      "Valid k-fold f1 scores [0.31290946 0.54221938 0.59712148 0.6403136  0.65931273]\n"
     ]
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    " \n",
    "print('Train k-fold f1 scores',  train_scores_mean)\n",
    "print('Valid k-fold f1 scores',  valid_scores_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно построить графики кривых обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Визуализируем кривую обучения\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) #фигура + координатная плоскость\n",
    "#Строим кривую обучения по метрикам на тренировочных фолдах\n",
    "ax.plot(train_sizes, train_scores_mean, label='Train')\n",
    "#Строим кривую обучения по метрикам на валидационных фолдах\n",
    "ax.plot(train_sizes, valid_scores_mean, label='Valid')\n",
    "#Даём название графику и подписи осям\n",
    "ax.set_title('Learning curve')\n",
    "ax.set_xlabel('Train data size')\n",
    "ax.set_ylabel('Score')\n",
    "#Устанавливаем отметки по оси абсцисс\n",
    "ax.xaxis.set_ticks(train_sizes)\n",
    "#Устаналиваем диапазон оси ординат\n",
    "ax.set_ylim(0, 1)\n",
    "#Отображаем легенду\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в процессе увеличения количества наблюдений в обучающем наборе данных, метрики на тренировочной и валидационной выборках постепенно приближаются друг к другу, то есть уменьшается разброс (variance).\n",
    "\n",
    "На финальном этапе, при использовании всех 2 620 наблюдений из обучающей выборки, разница в показателях между тренировочной и валидационной выборками всё ещё присутствует, однако эту разницу можно принять как случайную.\n",
    "\n",
    "***Для удобства дальнейшего использования описанных выше действий для построения кривой обучения давайте обернём их в функцию plot_learning_curve(). У функции будет несколько аргументов: модель, набор данных (X, y), кросс-валидатор, метрика, координатная плоскость matplotlib, на которой будет строиться график, и подпись графика:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X, y, cv, scoring=\"f1\", ax=None, title=\"\"):\n",
    "    # Вычисляем координаты для построения кривой обучения\n",
    "    train_sizes, train_scores, valid_scores = model_selection.learning_curve(\n",
    "        estimator=model,  # модель\n",
    "        X=X,  # матрица наблюдений X\n",
    "        y=y,  # вектор ответов y\n",
    "        cv=cv,  # кросс-валидатор\n",
    "        scoring=\"f1\",  # метрика\n",
    "    )\n",
    "    # Вычисляем среднее значение по фолдам для каждого набора данных\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    # Если координатной плоскости не было передано, создаём новую\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))  # фигура + координатная плоскость\n",
    "    # Строим кривую обучения по метрикам на тренировочных фолдах\n",
    "    ax.plot(train_sizes, train_scores_mean, label=\"Train\")\n",
    "    # Строим кривую обучения по метрикам на валидационных фолдах\n",
    "    ax.plot(train_sizes, valid_scores_mean, label=\"Valid\")\n",
    "    # Даём название графику и подписи осям\n",
    "    ax.set_title(\"Learning curve: {}\".format(title))\n",
    "    ax.set_xlabel(\"Train data size\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    # Устанавливаем отметки по оси абсцисс\n",
    "    ax.xaxis.set_ticks(train_sizes)\n",
    "    # Устанавливаем диапазон оси ординат\n",
    "    ax.set_ylim(0, 1)\n",
    "    # Отображаем легенду\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Примечание. Вы можете сохранить написанную нами функцию и обращаться к ней в своих задачах. Она не раз вам пригодится в исследованиях.***\n",
    "\n",
    "Теперь, когда у нас есть наша функция, давайте построим кривые обучения для нескольких моделей. Будем использовать следующие модели:\n",
    "\n",
    "- логистическую регрессию,\n",
    "- дерево решений с ограниченной максимальной глубиной и количеством объектов в листе,\n",
    "- дерево решений без ограничений.\n",
    "\n",
    "Создадим список, в котором будем хранить эти модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём список из моделей\n",
    "models = [\n",
    "    linear_model.LogisticRegression(\n",
    "        max_iter=1000, #количество итераций на сходимость\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        class_weight='balanced' #веса классов\n",
    "    ),\n",
    "    tree.DecisionTreeClassifier(\n",
    "        criterion='entropy', #критерий информативности\n",
    "        max_depth=7, #максимальная глубина\n",
    "        min_samples_leaf=5, #минимальное число объектов в листе\n",
    "        random_state=42, #генератор случайных чисел \n",
    "        class_weight='balanced' #веса классов\n",
    "    ),\n",
    "    tree.DecisionTreeClassifier(\n",
    "        criterion='entropy', #критерий информативности\n",
    "        random_state=42, #генератор случайных чисел \n",
    "        class_weight='balanced' #веса классов\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, построим кривые обучения для каждой из моделей. Для этого заранее создадим k-fold-кросс-валидатор со стратификацией на пять фолдов. Создадим фигуру с тремя координатными плоскостями. Реализуем цикл по составленному списку из моделей и их индексам (они нам понадобятся для отображения на соответствующих координатных плоскостях). Внутри цикла будем вызывать нашу функцию plot_learning_curve():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "#Визуализируем кривые обучения\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4)) #фигура + три координатных плоскости\n",
    "#Создаём цикл по списку моделей и индексам этого списка\n",
    "for i, model in enumerate(models): #i — текущий индекс, model — текущая модель\n",
    "    plot_learning_curve(model, X, y, skf, ax=axes[i], title=f'model {i+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря построенным графикам мы можем легко сравнить три представленные модели между собой. \n",
    "\n",
    "- Первый график, построенный для логистической регрессии, говорит нам о том, что для данной модели качество на тренировочных и валидационных фолдах практически одинаково (кривые проходят очень близко друг к другу), то есть переобучения нет. Однако данная модель обладает низким качеством: кривые не превышают даже значения 0.5. Модель является недообученнной.\n",
    "- Третий график, построенный для дерева решений без ограничений глубины, явно указывает на наличие переобучения: тренировочная кривая всё время находится в области своего максимума — 1, а вот валидационная кривая не может достичь такой высокой отметки.\n",
    "- Из всех представленных оптимальной является модель дерева решений с ограничениями, кривая обучения которой изображена на втором графике. Тренировочная и валидационная кривые постепенно сходятся к единой отметке качества, и полученная метрика превышает отметку в 0.5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e35777b699d7a7b40cec7735ff85abf8ad01a2c5ba9ffe1b0b11d4c2052d3903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
